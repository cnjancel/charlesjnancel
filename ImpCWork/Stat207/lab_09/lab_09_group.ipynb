{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 207 Lab Assignment 9 - Group Part - 9 points\n",
    "\n",
    "\n",
    "# <u>Case Study</u>: Exploring the Impact of Scaling on Regularization Models\n",
    "\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Let's return to the dataset that was used in our Midterm 1 exam. The data in the `video_game_sales_sample.csv` file contains information about a sample of video games released between 1995 and 2016.\n",
    "\n",
    "* `NA_Sales`: yearly total European sales (in millions of dollars) of the video game\n",
    "* `EU_Sales`: yearly total European sales (in millions of dollars) of the video game\n",
    "* `JP_Sales`: yearly total Japanese sales (in millions of dollars) of the video game\n",
    "* `Other_Sales`: yearly total sales in other countries (in millions of dollars) of the video game\n",
    "* `Year`: the year that video game was released\n",
    "* `Genre`: (just considering action or strategy in this analysis) genre of the video game\n",
    "* `Platform`: (just considering PS, PS2, PS3, DS, and Wii in this analysis) platform of the video game\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "We would like to explore how a resulting regularization model output might change based on the scale of the explanatory variables.\n",
    "\n",
    "\n",
    "## Points\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<table style=\"border: none;border-collapse: collapse;width:102pt;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;width:51pt;\">Problem</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid black;border-left:none;width:51pt;\">Points</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">1.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">1.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">1.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">1.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">1.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">2.2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">2.2.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">2.2.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">2.2.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">2.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">3.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">3.2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">3.2.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">3.2.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">3.2.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">3.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">4.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">4.2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">4.2.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">4.2.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">4.2.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.25</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;height:14.25pt;border-top:none;\">4.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid black;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Data Examination and Cleaning\n",
    "\n",
    "### 1.1. Reading the Dataset and Detecing Any Implicit Missing Values\n",
    "\n",
    "1. **Reading and Implicit Missing Value Conversion**: Read this csv file into a dataframe. This csv file may contains implicit missing values in our intended numerical variables! Make sure that when you read your csv file into your dataframe (the final time), that any implicit missing values in the numerical variable columns have been converted into NaN values.\n",
    "\n",
    "2. **Display your dataframe.**\n",
    "\n",
    "3. **Show how many rows your dataframe has.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vg = pd.read_csv('video_game_sales_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales', 'Year']\n",
    "for col in numerical_columns:\n",
    "    vg[col] = pd.to_numeric(vg[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saints Row IV</td>\n",
       "      <td>PS3</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Treasures of the Deep</td>\n",
       "      <td>PS</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skylanders: Spyro's Adventure</td>\n",
       "      <td>Wii</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LEGO Batman: The Videogame</td>\n",
       "      <td>PS2</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Carnage Heart</td>\n",
       "      <td>PS</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name Platform    Year     Genre  NA_Sales  \\\n",
       "0                  Saints Row IV      PS3  2013.0    Action      0.56   \n",
       "1          Treasures of the Deep       PS  1997.0    Action      0.10   \n",
       "2  Skylanders: Spyro's Adventure      Wii  2011.0    Action      1.40   \n",
       "3     LEGO Batman: The Videogame      PS2  2008.0    Action      0.72   \n",
       "4                  Carnage Heart       PS  1995.0  Strategy      0.01   \n",
       "\n",
       "   EU_Sales  JP_Sales  Other_Sales  \n",
       "0      0.44      0.09         0.21  \n",
       "1      0.07      0.00         0.01  \n",
       "2      1.14      0.00         0.31  \n",
       "3      0.03      0.00         0.52  \n",
       "4      0.01      0.09         0.01  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows = vg.shape[0]\n",
    "num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dropping Unneeded Variables\n",
    "\n",
    "We only intend to use the `NA_Sales, EU_Sales, JP_Sales, Other_Sales, and Year` variables in this analysis. Drop all other variables from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Platform</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PS3</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PS</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wii</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PS2</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Action</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PS</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Strategy</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Platform    Year     Genre  NA_Sales  EU_Sales  JP_Sales  Other_Sales\n",
       "0      PS3  2013.0    Action      0.56      0.44      0.09         0.21\n",
       "1       PS  1997.0    Action      0.10      0.07      0.00         0.01\n",
       "2      Wii  2011.0    Action      1.40      1.14      0.00         0.31\n",
       "3      PS2  2008.0    Action      0.72      0.03      0.00         0.52\n",
       "4       PS  1995.0  Strategy      0.01      0.01      0.09         0.01"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vg_cleaned = vg\n",
    "vg_cleaned = vg_cleaned.drop(columns=['Name'])\n",
    "\n",
    "vg_cleaned_head = vg_cleaned.head()\n",
    "vg_cleaned_head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Dropping Missing Values\n",
    "\n",
    "Drop all rows in this dataframe with a missing value. How many rows did you drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vg_cleaned = vg.dropna()\n",
    "\n",
    "vg_cleaned.reset_index(drop=True, inplace=True)\n",
    "\n",
    "rows_dropped = num_rows - vg_cleaned.shape[0]\n",
    "\n",
    "vg_cleaned_head = vg_cleaned.head()\n",
    "rows_dropped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Features Matrix and Target Array \n",
    "\n",
    "Use this full dataset (ie. not one that has been split into training or test dataset) to create a features matrix and target array for our linear regression models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vg_cleaned.drop(columns=['NA_Sales'])\n",
    "y = vg_cleaned['NA_Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                            Name Platform    Year     Genre  EU_Sales  \\\n",
       " 0                  Saints Row IV      PS3  2013.0    Action      0.44   \n",
       " 1          Treasures of the Deep       PS  1997.0    Action      0.07   \n",
       " 2  Skylanders: Spyro's Adventure      Wii  2011.0    Action      1.14   \n",
       " 3     LEGO Batman: The Videogame      PS2  2008.0    Action      0.03   \n",
       " 4                  Carnage Heart       PS  1995.0  Strategy      0.01   \n",
       " \n",
       "    JP_Sales  Other_Sales  \n",
       " 0      0.09         0.21  \n",
       " 1      0.00         0.01  \n",
       " 2      0.00         0.31  \n",
       " 3      0.00         0.52  \n",
       " 4      0.09         0.01  ,\n",
       " 0    0.56\n",
       " 1    0.10\n",
       " 2    1.40\n",
       " 3    0.72\n",
       " 4    0.01\n",
       " Name: NA_Sales, dtype: float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_head = X.head()\n",
    "y_head = y.head()\n",
    "\n",
    "X_head, y_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Features Matrix Scales\n",
    "\n",
    "Calculate the standard deviation of each variable in your features matrix. Would we be able to interpret the magnitude of the slopes in any resulting linear regression model as an indication of how important the corresponding explanatory variable is when it comes to predict `NA_Sales`? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547725</td>\n",
       "      <td>0.557583</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>0.679615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.300538</td>\n",
       "      <td>-0.212010</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.096726</td>\n",
       "      <td>2.013569</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>1.163142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.842772</td>\n",
       "      <td>-0.295209</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>2.178547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.466502</td>\n",
       "      <td>-0.336809</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NA_Sales  EU_Sales  JP_Sales  Other_Sales\n",
       "0  0.547725  0.557583  0.155697     0.679615\n",
       "1 -0.300538 -0.212010 -0.377494    -0.287438\n",
       "2  2.096726  2.013569 -0.377494     1.163142\n",
       "3  0.842772 -0.295209 -0.377494     2.178547\n",
       "4 -0.466502 -0.336809  0.155697    -0.287438"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "numerical_columns.remove('Year')\n",
    "vg_numerical = vg_cleaned[numerical_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "vg_scaled = scaler.fit_transform(vg_numerical)\n",
    "vg_scaled_df = pd.DataFrame(vg_scaled, columns=numerical_columns)\n",
    "\n",
    "vg_scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing the features, the magnitude of the coefficients in a linear regression model can be used as an indication of the relative importance of the corresponding explanatory variables when predicting `NA_Sales`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Elastic Net Models with Unscaled Features Matrix\n",
    "\n",
    "Let's first build a few elastic net models with an $\\alpha=0.9$, using our *unscaled* features matrix.\n",
    "\n",
    "### 2.1. Elastic Net Slopes\n",
    "\n",
    "By setting $\\alpha=0.9$ (ie the $l1\\_ratio=0.9$), would we expect our resulting elastic net linear regression slopes to look more like what a LASSO model would return or a ridge regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Elastic Net regularization method is a combination of L1 and L2 regularization. It has a mix of both LASSO and Ridge regression properties. The parameter $ \\alpha $ (or $ l1\\_ratio $ in some implementations) determines the balance between L1 and L2 regularization.\n",
    "\n",
    "- When $ \\alpha = 1 $ (or $ l1\\_ratio = 1 $), Elastic Net is equivalent to LASSO regression (uses only L1 regularization).\n",
    "- When $ \\alpha = 0 $ (or $ l1\\_ratio = 0 $), Elastic Net is equivalent to Ridge regression (uses only L2 regularization).\n",
    "- For values between 0 and 1, Elastic Net uses a mix of both L1 and L2 regularization.\n",
    "\n",
    "Given that $ \\alpha = 0.9 $ (or $ l1\\_ratio = 0.9 $), this means that the model will have a strong LASSO component (90% L1 regularization) and a smaller Ridge component (10% L2 regularization).\n",
    "\n",
    "Thus, with $ \\alpha = 0.9 $, we would expect our resulting Elastic Net linear regression slopes to look **more like what a LASSO model would return** than a Ridge regression model. Specifically, it would tend towards zeroing out some of the coefficients, a characteristic behavior of LASSO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Explanatory Variable Important in an Elastic Net Model\n",
    "\n",
    "#### 2.2.1 All Zero Slopes\n",
    "\n",
    "First, find a value of $\\lambda$ in an elastic net model with $\\alpha=0.9$ that will yield ALL slopes being equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24770763559917114"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Extracting the features and target variable\n",
    "X_unscaled = vg_numerical.drop(columns='NA_Sales')\n",
    "y = vg_cleaned['NA_Sales']\n",
    "\n",
    "# List of alphas (lambdas) to test\n",
    "alphas = np.logspace(-4, 4, 100)\n",
    "\n",
    "# Placeholder for coefficients\n",
    "coef_list = []\n",
    "\n",
    "# Fit ElasticNet for each alpha\n",
    "for alpha in alphas:\n",
    "    enet = ElasticNet(alpha=alpha, l1_ratio=0.9, max_iter=10000)\n",
    "    enet.fit(X_unscaled, y)\n",
    "    coef_list.append(enet.coef_)\n",
    "\n",
    "# Finding the smallest alpha (lambda) where all coefficients are approximately zero\n",
    "alpha_for_zero_coeff = None\n",
    "for alpha, coef in zip(alphas, coef_list):\n",
    "    if all(np.isclose(coef, 0, atol=1e-5)):\n",
    "        alpha_for_zero_coeff = alpha\n",
    "        break\n",
    "\n",
    "alpha_for_zero_coeff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 One Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model with $\\alpha=0.9$ that will yield ONE non-zero slope. What explanatory variable corresponds to this non-zero slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.012618568830660211, 'EU_Sales')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholder for alpha (lambda) and the corresponding non-zero feature\n",
    "alpha_for_one_nonzero_coeff = None\n",
    "nonzero_feature = None\n",
    "\n",
    "# Iterate through alphas and coefficients to find the desired condition\n",
    "for alpha, coef in zip(alphas, coef_list):\n",
    "    # Check if exactly one coefficient is non-zero\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 1:\n",
    "        alpha_for_one_nonzero_coeff = alpha\n",
    "        nonzero_feature = X_unscaled.columns[~np.isclose(coef, 0, atol=1e-5)][0]\n",
    "        break\n",
    "\n",
    "alpha_for_one_nonzero_coeff, nonzero_feature\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 Two Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model with $\\alpha=0.9$ that will yield TWO non-zero slopeS. What explanatory variableS corresponds to these non-zero slopes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.005994842503189409, ['EU_Sales', 'Other_Sales'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholder for alpha (lambda) and the corresponding non-zero features\n",
    "alpha_for_two_nonzero_coeffs = None\n",
    "nonzero_features = []\n",
    "\n",
    "# Iterate through alphas and coefficients to find the desired condition\n",
    "for alpha, coef in zip(alphas, coef_list):\n",
    "    # Check if exactly two coefficients are non-zero\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 2:\n",
    "        alpha_for_two_nonzero_coeffs = alpha\n",
    "        nonzero_features = list(X_unscaled.columns[~np.isclose(coef, 0, atol=1e-5)])\n",
    "        break\n",
    "\n",
    "alpha_for_two_nonzero_coeffs, nonzero_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 Three Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model with $\\alpha=0.9$ that will yield THREE non-zero slopes. What explanatory variables corresponds to these non-zero slopes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, ['EU_Sales', 'JP_Sales', 'Other_Sales'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholder for alpha (lambda) and the corresponding non-zero features\n",
    "alpha_for_three_nonzero_coeffs = None\n",
    "nonzero_features_three = []\n",
    "\n",
    "# Iterate through alphas and coefficients to find the desired condition\n",
    "for alpha, coef in zip(alphas, coef_list):\n",
    "    # Check if exactly three coefficients are non-zero\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 3:\n",
    "        alpha_for_three_nonzero_coeffs = alpha\n",
    "        nonzero_features_three = list(X_unscaled.columns[~np.isclose(coef, 0, atol=1e-5)])\n",
    "        break\n",
    "\n",
    "alpha_for_three_nonzero_coeffs, nonzero_features_three\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Interpretation\n",
    "\n",
    "When using an unscaled features matrix in an elastic net model with an $\\alpha=0.9$, which explanatory variable is determined to bring:\n",
    "* the most predictive power to the model, \n",
    "* the second most predictive power to the model, \n",
    "* the third most predictive power to the model, \n",
    "* the fourth most predictive power to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given the coefficients obtained from the Elastic Net model with $ \\alpha = 0.9 \\) on the unscaled features matrix:\n",
    "\n",
    "1. **Most predictive power**: The variable with the highest absolute coefficient value is seen to bring the most predictive power to the model. \n",
    "2. **Second most predictive power**: The variable with the second highest absolute coefficient value.\n",
    "3. **Third most predictive power**: The variable with the third highest absolute coefficient value.\n",
    "4. **Fourth most predictive power**: The variable with the fourth highest absolute coefficient value.\n",
    "\n",
    "Based on the Elastic Net model with $ \\alpha = 0.9 \\) and the unscaled features matrix, the explanatory variables are determined to bring the following predictive power to the model:\n",
    "\n",
    "1. **Most predictive power**: `EU_Sales`\n",
    "2. **Second most predictive power**: `Other_Sales`\n",
    "3. **Third most predictive power**: `JP_Sales`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Elastic Net Models with Scales Features Matrix\n",
    "\n",
    "Now let's build a few elastic net models with an $\\alpha=0.9$, and a *scaled* features matrix.\n",
    "\n",
    "### 3.1. Scaling the Features Matrix\n",
    "\n",
    "First, z-score scale your features matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.557583</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>0.679615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.212010</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.013569</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>1.163142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.295209</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>2.178547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.336809</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EU_Sales  JP_Sales  Other_Sales\n",
       "0  0.557583  0.155697     0.679615\n",
       "1 -0.212010 -0.377494    -0.287438\n",
       "2  2.013569 -0.377494     1.163142\n",
       "3 -0.295209 -0.377494     2.178547\n",
       "4 -0.336809  0.155697    -0.287438"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = vg_cleaned[['EU_Sales', 'JP_Sales', 'Other_Sales']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=['EU_Sales', 'JP_Sales', 'Other_Sales'])\n",
    "\n",
    "X_scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Explanatory Variable Important in an Elastic Net Model\n",
    "\n",
    "#### 3.2.1 All Zero Slopes\n",
    "\n",
    "First, find a value of $\\lambda$ in an elastic net model (which uses the scaled features matrix) with $\\alpha=0.9$ that will yield ALL slopes being equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521400828799969"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_list_scaled = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    enet_scaled = ElasticNet(alpha=alpha, l1_ratio=0.9, max_iter=10000)\n",
    "    enet_scaled.fit(X_scaled, y)\n",
    "    coef_list_scaled.append(enet_scaled.coef_)\n",
    "\n",
    "alpha_for_zero_coeff_scaled = None\n",
    "for alpha, coef in zip(alphas, coef_list_scaled):\n",
    "    if all(np.isclose(coef, 0, atol=1e-5)):\n",
    "        alpha_for_zero_coeff_scaled = alpha\n",
    "        break\n",
    "\n",
    "alpha_for_zero_coeff_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 One Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model (which uses the scaled features matrix) with $\\alpha=0.9$ that will yield ONE non-zero slope. What explanatory variable corresponds to this non-zero slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.24770763559917114, 'EU_Sales')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_for_one_nonzero_coeff_scaled = None\n",
    "nonzero_feature_scaled = None\n",
    "\n",
    "for alpha, coef in zip(alphas, coef_list_scaled):\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 1:\n",
    "        alpha_for_one_nonzero_coeff_scaled = alpha\n",
    "        nonzero_feature_scaled = X_scaled_df.columns[~np.isclose(coef, 0, atol=1e-5)][0]\n",
    "        break\n",
    "\n",
    "alpha_for_one_nonzero_coeff_scaled, nonzero_feature_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Two Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model (which uses the scaled features matrix) with $\\alpha=0.9$ that will yield TWO non-zero slopeS. What explanatory variableS corresponds to these non-zero slopes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.04641588833612782, ['EU_Sales', 'Other_Sales'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_for_two_nonzero_coeffs_scaled = None\n",
    "nonzero_features_scaled = []\n",
    "\n",
    "for alpha, coef in zip(alphas, coef_list_scaled):\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 2:\n",
    "        alpha_for_two_nonzero_coeffs_scaled = alpha\n",
    "        nonzero_features_scaled = list(X_scaled_df.columns[~np.isclose(coef, 0, atol=1e-5)])\n",
    "        break\n",
    "\n",
    "alpha_for_two_nonzero_coeffs_scaled, nonzero_features_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Three Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model (which uses the scaled features matrix) with $\\alpha=0.9$ that will yield THREE non-zero slopes. What explanatory variables corresponds to these non-zero slopes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, ['EU_Sales', 'JP_Sales', 'Other_Sales'])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_for_three_nonzero_coeffs_scaled = None\n",
    "nonzero_features_three_scaled = []\n",
    "\n",
    "for alpha, coef in zip(alphas, coef_list_scaled):\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 3:\n",
    "        alpha_for_three_nonzero_coeffs_scaled = alpha\n",
    "        nonzero_features_three_scaled = list(X_scaled_df.columns[~np.isclose(coef, 0, atol=1e-5)])\n",
    "        break\n",
    "\n",
    "alpha_for_three_nonzero_coeffs_scaled, nonzero_features_three_scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Interpretation\n",
    "\n",
    "When using a scale features matrix in an elastic net model with an $\\alpha=0.9$, which explanatory variable is determined to bring:\n",
    "* the most predictive power to the model, \n",
    "* the second most predictive power to the model, \n",
    "* the third most predictive power to the model, \n",
    "* the fourth most predictive power to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address this, let's revisit the coefficients obtained from the Elastic Net model with $ \\alpha = 0.9 $ on the scaled features matrix:\n",
    "\n",
    "1. **Most predictive power**: The variable with the highest absolute coefficient value is deemed to bring the most predictive power to the model.\n",
    "2. **Second most predictive power**: The variable with the second highest absolute coefficient value.\n",
    "3. **Third most predictive power**: The variable with the third highest absolute coefficient value.\n",
    "4. **Fourth most predictive power**: The variable with the fourth highest absolute coefficient value.\n",
    "\n",
    "When we decrease $ \\lambda $ from a large value:\n",
    "\n",
    "- The first variable to have a non-zero coefficient is typically the one that provides the most predictive power, given the regularization constraints.\n",
    "- The second variable to become non-zero is the second most predictive, and so on.\n",
    "\n",
    "From our previous exercises:\n",
    "1. `EU_Sales` was the first to become non-zero.\n",
    "2. `Other_Sales` was the second to become non-zero.\n",
    "3. `JP_Sales` was the third to become non-zero.\n",
    "\n",
    "Thus, based on the order of non-zero slopes, `EU_Sales` has the most predictive power, followed by `Other_Sales`, and then `JP_Sales`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Elastic Net Models with Scales Features Matrix\n",
    "\n",
    "Now let's build a few elastic net models with an $\\alpha=0.9$, and a *scaled* features matrix in which the `EU_Sales` variable has been additionally \"downweighted\". EU_Sales was deemed to bring a high amount of predictive power to the models in #2 and #3. Will it continue to do so when it's scale has been \"downweighted\"?\n",
    "\n",
    "### 4.1. Downweighting the the EU_Sales Variable\n",
    "\n",
    "Now, take your scaled features matrix and multiply the `EU_Sales` variable by 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>0.679615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002014</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>1.163142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.377494</td>\n",
       "      <td>2.178547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000337</td>\n",
       "      <td>0.155697</td>\n",
       "      <td>-0.287438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EU_Sales  JP_Sales  Other_Sales\n",
       "0  0.000558  0.155697     0.679615\n",
       "1 -0.000212 -0.377494    -0.287438\n",
       "2  0.002014 -0.377494     1.163142\n",
       "3 -0.000295 -0.377494     2.178547\n",
       "4 -0.000337  0.155697    -0.287438"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_df_downweighted = X_scaled_df.copy()\n",
    "X_scaled_df_downweighted['EU_Sales'] = X_scaled_df_downweighted['EU_Sales'] * 0.001\n",
    "\n",
    "X_scaled_df_downweighted.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Explanatory Variable Important in an Elastic Net Model\n",
    "\n",
    "#### 4.2.1 All Zero Slopes\n",
    "\n",
    "First, find a value of $\\lambda$ in an elastic net model (which uses this new features matrix) with $\\alpha=0.9$ that will yield ALL slopes being equal to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521400828799969"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_list_downweighted = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    enet_downweighted = ElasticNet(alpha=alpha, l1_ratio=0.9, max_iter=10000)\n",
    "    enet_downweighted.fit(X_scaled_df_downweighted, y)\n",
    "    coef_list_downweighted.append(enet_downweighted.coef_)\n",
    "\n",
    "alpha_for_zero_coeff_downweighted = None\n",
    "for alpha, coef in zip(alphas, coef_list_downweighted):\n",
    "    if all(np.isclose(coef, 0, atol=1e-5)):\n",
    "        alpha_for_zero_coeff_downweighted = alpha\n",
    "        break\n",
    "\n",
    "alpha_for_zero_coeff_downweighted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 One Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model (which uses this new features matrix) with $\\alpha=0.9$ that will yield ONE non-zero slope. What explanatory variable corresponds to this non-zero slope?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08111308307896872, 'Other_Sales')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_for_one_nonzero_coeff_downweighted = None\n",
    "nonzero_feature_downweighted = None\n",
    "\n",
    "for alpha, coef in zip(alphas, coef_list_downweighted):\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 1:\n",
    "        alpha_for_one_nonzero_coeff_downweighted = alpha\n",
    "        nonzero_feature_downweighted = X_scaled_df_downweighted.columns[~np.isclose(coef, 0, atol=1e-5)][0]\n",
    "        break\n",
    "\n",
    "alpha_for_one_nonzero_coeff_downweighted, nonzero_feature_downweighted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Two Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model (which uses this new features matrix) with $\\alpha=0.9$ that will yield TWO non-zero slopeS. What explanatory variableS corresponds to these non-zero slopes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.000145082877849594, ['JP_Sales', 'Other_Sales'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_for_two_nonzero_coeffs_downweighted = None\n",
    "nonzero_features_two_downweighted = []\n",
    "\n",
    "for alpha, coef in zip(alphas, coef_list_downweighted):\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 2:\n",
    "        alpha_for_two_nonzero_coeffs_downweighted = alpha\n",
    "        nonzero_features_two_downweighted = list(X_scaled_df_downweighted.columns[~np.isclose(coef, 0, atol=1e-5)])\n",
    "        break\n",
    "\n",
    "alpha_for_two_nonzero_coeffs_downweighted, nonzero_features_two_downweighted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Three Non-Zero Slopes\n",
    "\n",
    "Find a value of $\\lambda$ in an elastic net model (which uses this new features matrix) with $\\alpha=0.9$ that will yield THREE non-zero slopes. What explanatory variables corresponds to these non-zero slopes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, ['EU_Sales', 'JP_Sales', 'Other_Sales'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_for_three_nonzero_coeffs_downweighted = None\n",
    "nonzero_features_three_downweighted = []\n",
    "\n",
    "for alpha, coef in zip(alphas, coef_list_downweighted):\n",
    "    if sum(~np.isclose(coef, 0, atol=1e-5)) == 3:\n",
    "        alpha_for_three_nonzero_coeffs_downweighted = alpha\n",
    "        nonzero_features_three_downweighted = list(X_scaled_df_downweighted.columns[~np.isclose(coef, 0, atol=1e-5)])\n",
    "        break\n",
    "\n",
    "alpha_for_three_nonzero_coeffs_downweighted, nonzero_features_three_downweighted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Interpretation\n",
    "\n",
    "When using this new features matrix in an elastic net model with an $\\alpha=0.9$, which explanatory variable is determined to bring:\n",
    "* the most predictive power to the model, \n",
    "* the second most predictive power to the model, \n",
    "* the third most predictive power to the model, \n",
    "* the fourth most predictive power to the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The order in which coefficients become non-zero as we decrease \\( \\lambda \\) in the context of LASSO or Elastic Net regularization can provide insights into the relative importance or predictive power of each feature. \n",
    "\n",
    "1. **Most predictive power**: The first variable to have a non-zero coefficient was `Other_Sales`. This suggests that `Other_Sales` provides the most predictive power to the model given the regularization constraints when `EU_Sales` is downweighted.\n",
    "2. **Second most predictive power**: The second variable to become non-zero was `JP_Sales`, indicating it's the second most predictive.\n",
    "3. **Third most predictive power**: `EU_Sales` was the third variable to become non-zero, suggesting it's the third most predictive when downweighted.\n",
    "\n",
    "Given this sequence of non-zero coefficients, we can infer the relative importance of each explanatory variable in predicting `NA_Sales` in the context of the downweighted features matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning Outcome\n",
    "\n",
    "Do you think that the scale of the explanatory variables in the features matrix influences which explanatory variables are deemed to bring  \"enough\" predictive power to a regularization model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scale of explanatory variables plays a pivotal role in regularization models, particularly those with L1 penalties like LASSO and Elastic Net. \n",
    "\n",
    "When variables possess varying scales, regularization might unjustly penalize larger-scale variables even if they're intrinsically crucial predictors. This disparity can distort the perceived importance of features. Therefore, if you're aiming to interpret the predictive power of specific explanatory variables using a regularization model, it's paramount to standardize these variables, especially if they don't share relatively similar standard deviations. \n",
    "\n",
    "By scaling the variables (often to a mean of 0 and a standard deviation of 1), each gets an equitable footing in terms of scale. This uniformity ensures that the regularization penalty is applied consistently across all variables, facilitating a more genuine interpretation of each variable's predictive power.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Tip</u>\n",
    "\n",
    "**If you plan to use a regularization model to interpret how much predictive power a given explanatory brings to a model, you should scale your explanatory variables first if they do not have relatively similar standard deviations!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sophie and I worked together for the entire lab, and we split up 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
