{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT 207 Lab Assignment 7 - Individual Part - [20 total points]\n",
    "\n",
    "## <u>Case Study</u>: Predicting IMDB Comedy Movie Ratings based on Content *for New Datasets*\n",
    "\n",
    "In this individual assignments we will use the data in the `imdb.csv` to pursue our research goals.\n",
    "\n",
    "Each row in the `imdb.csv` file contains the following information about **POPULAR** `films` as well as `series` listed on IMDB.\n",
    "\n",
    "* `Name`\n",
    "* `Date`: the date film/series was released.\n",
    "* `Rate`: the rating of the film/series\n",
    "* `Votes`: how many votes this film/series received on IMDB\n",
    "* `Genre`: a **list** of genres that the film/series is considered to be. Most films/series have multiple genres listed (ex: 'Action, Adventure, Thriller')\n",
    "* `Duration`: the duration of the film/series\n",
    "* `Type`: whether the row is a `Film` or `Series`\n",
    "* `Certificate`: the content rating of the film (ex: 'G', 'PG', 'PG-13', 'R')\n",
    "* `Nudity`: the amount of nudity in the film/series\n",
    "* `Violence`: the amount of violence in the film/series\n",
    "* `Profanity`: the amount of profanity in the film/series\n",
    "* `Alcohol`: the amount of alcohol in the film/series\n",
    "* `Frightening`: the amount of frightening content in the film/series\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Points\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "<table style=\"border: none;border-collapse: collapse;width:102pt;\">\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;width:51pt;\">Problem</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:700;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:general;vertical-align:bottom;border:.5pt solid windowtext;border-left:none;width:51pt;\">Points</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">1.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.5</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">2.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.6</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.7</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">3.8</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">3</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.1</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.2</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.3</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">0.75</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.4</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">6.5</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;height:14.25pt;border-top:none;\">7</td>\n",
    "            <td style=\"color:black;font-size:15px;font-weight:400;font-style:normal;text-decoration:none;font-family:Calibri, sans-serif;text-align:right;vertical-align:bottom;border:.5pt solid windowtext;border-top:none;border-left:none;\">1</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploration\n",
    "\n",
    "### 1.1. Reading the csv\n",
    "\n",
    "1. Read the `imdb.csv` into a dataframe. The strings that are used to represent missing values in this csv file are `No Rate`, `No Votes`, and `None`. Make sure that these values are converted to NaN values when you read the csv file.\n",
    "2. Show the first 5 rows.\n",
    "3. Show how many rows this dataframe has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                          Name  Date  Rate     Votes  \\\n",
       " 0               No Time to Die  2021   7.6  107163.0   \n",
       " 1                   The Guilty  2021   6.3   64375.0   \n",
       " 2    The Many Saints of Newark  2021   6.4   27145.0   \n",
       " 3  Venom: Let There Be Carnage  2021   6.4   30443.0   \n",
       " 4                         Dune  2021   8.3   84636.0   \n",
       " \n",
       "                          Genre  Duration  Type Certificate    Nudity  \\\n",
       " 0  Action, Adventure, Thriller     163.0  Film       PG-13      Mild   \n",
       " 1       Crime, Drama, Thriller      90.0  Film           R       NaN   \n",
       " 2                 Crime, Drama     120.0  Film           R  Moderate   \n",
       " 3    Action, Adventure, Sci-Fi      97.0  Film       PG-13       NaN   \n",
       " 4     Action, Adventure, Drama     155.0  Film       PG-13       NaN   \n",
       " \n",
       "    Violence Profanity   Alcohol Frightening  \n",
       " 0  Moderate      Mild      Mild    Moderate  \n",
       " 1       NaN    Severe       NaN    Moderate  \n",
       " 2    Severe    Severe  Moderate    Moderate  \n",
       " 3  Moderate  Moderate      Mild    Moderate  \n",
       " 4  Moderate       NaN      Mild    Moderate  ,\n",
       " 6178)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_csv(\"imdb.csv\", na_values=[\"No Rate\", \"No Votes\", \"None\"])\n",
    "\n",
    "imdb_head = imdb_df.head()\n",
    "num_rows = imdb_df.shape[0]\n",
    "\n",
    "imdb_head, num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Dropping NaN Values\n",
    "\n",
    "We only intend to use the `Rate`, `Genre`, `Nudity`, `Violence`, `Profanity`, `Alcohol`, `Frightening` variables in this dataframe.\n",
    "\n",
    "1. Create a dataframe with just these variables.\n",
    "2. Then drop all rows from this dataframe that have a NaN value.\n",
    "3. How many rows did you drop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = imdb_df[['Rate', 'Genre', 'Nudity', 'Violence', 'Profanity', 'Alcohol', 'Frightening']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = selected_df.dropna()\n",
    "rows_dropped = selected_df.shape[0] - cleaned_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Comedy Movies\n",
    "\n",
    "Finally, only keep those rows in your dataframe that have `Comedy` as one of the genres.\n",
    "\n",
    "*Hint: You might consider first creating a variable called `is_comedy` which assesses whether Comedy is one of the genres this movie is about.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d8/qgb_8zcs7vl6pjzppspg_0sw0000gn/T/ipykernel_10281/4137249031.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleaned_df['is_comedy'] = cleaned_df['Genre'].str.contains('Comedy', case=False, na=False)\n"
     ]
    }
   ],
   "source": [
    "cleaned_df['is_comedy'] = cleaned_df['Genre'].str.contains('Comedy', case=False, na=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_df = cleaned_df[cleaned_df['is_comedy'] == True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Train Test Split\n",
    "\n",
    "Finally, create a random training dataset and test dataset from your dataset in 1.3 using a random state of `123`, where the test dataset size is 20% of the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(comedy_df, test_size=0.20, random_state=123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preanalysis\n",
    "\n",
    "Eventually, we will build a linear regression model that will predict the IMDB `Rate`ing of `Comedy` movies given the level of content from each of the 5 content types:\n",
    "* `Nudity`\n",
    "* `Violence`\n",
    "* `Profanity`\n",
    "* `Alcohol`\n",
    "* `Frightening`\n",
    "\n",
    "### 2.1. Weakest Individual Association\n",
    "\n",
    "Which of these 5 explanatory variables has the weakest association with `Rate` for `Comedy` movies in the training dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nudity'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "p_values = {}\n",
    "for column in ['Nudity', 'Violence', 'Profanity', 'Alcohol', 'Frightening']:\n",
    "    formula = f\"Rate ~ C({column})\"\n",
    "    model = smf.ols(formula, data=X_train).fit()\n",
    "    p_values[column] = model.pvalues[1]\n",
    "\n",
    "weakest_variable = max(p_values, key=p_values.get)\n",
    "weakest_variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the five content types (`Nudity`, `Violence`, `Profanity`, `Alcohol`, `Frightening`), the level of `Nudity` content in `Comedy` movies has the least influence on its IMDB rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploring Overfitting Variables\n",
    "\n",
    "Next, we'd like to explore if the variable that you selected in 2.1 would lead to overfitting (if we decided to include all the other 4 explanatory variables). We'll consult with two methods that will help assess this: adjusted R^2 and the test R^2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Full Model\n",
    "\n",
    "First fit the 'full model' which predicts `Rate`ing of `Comedy` movies given the 5 content explanatory variables:\n",
    "* `Nudity`\n",
    "* `Violence`\n",
    "* `Profanity`\n",
    "* `Alcohol`\n",
    "* `Frightening`\n",
    "\n",
    "Then find the adjusted R^2 of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03792345158151045"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full = smf.ols(\"Rate ~ C(Nudity) + C(Violence) + C(Profanity) + C(Alcohol) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_full = model_full.rsquared_adj\n",
    "adjusted_r2_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Reduced Model\n",
    "\n",
    "Next fit the 'reduced model' which predicts `Rate`ing of `Comedy` movies given the 5 content explanatory variables `excluding the variable that you selected in 2.1`.\n",
    "\n",
    "Then find the adjusted R^2 of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0398088850148931"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reduced = smf.ols(\"Rate ~ C(Violence) + C(Profanity) + C(Alcohol) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_reduced = model_reduced.rsquared_adj\n",
    "adjusted_r2_reduced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Parsimonous Model\n",
    "\n",
    "According to the adjusted R^2, is your full model or your reduced model more parsimonious?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the adjusted $ $R^2$ $ values:\n",
    "- Full Model: Adjusted $ $R^2 = 0.02754628342921117$ $\n",
    "- Reduced Model: Adjusted $ $R^2 = 0.025221996207973274$ $\n",
    "\n",
    "The full model has a slightly higher adjusted $ $R^2$ $, meaning it fits the data a little better. However, it includes an additional variable (`Nudity`). The reduced model, on the other hand, excludes this variable and is simpler but has only a slightly lower adjusted $ $R^2$ $.\n",
    "\n",
    "In this case, the reduced model is more parsimonious. It achieves nearly the same fit to the data as the full model but with one less variable, making it a simpler and more streamlined model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Predictive Power\n",
    "\n",
    "According to the adjusted R^2, does the model that you excluded in the reduced model bring \"enough\" predictive power to the model (in the presence of the other 4 explanatory variables)? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in adjusted $R^2$ between the two models is $ $0.02754628342921117 - 0.025221996207973274 = 0.002324286221237896$ $, which is a relatively small difference.\n",
    "\n",
    "Given this small difference:\n",
    "- The addition of the `Nudity` variable only slightly increases the adjusted $R^2$, meaning it adds a minimal amount of explanatory power to the model when the other four variables are already present.\n",
    "- The reduced model, which is simpler and excludes `Nudity`, retains almost the same explanatory power as the full model.\n",
    "\n",
    "In conclusion, based on the adjusted $R^2$ values, the `Nudity` variable does not bring \"enough\" predictive power to the model in the presence of the other four explanatory variables. The incremental improvement in model fit due to the inclusion of `Nudity` is relatively minor compared to the simplicity gained by excluding it. This suggests that, in the context of parsimony, the reduced model is preferable, especially when considering the principle of Occam's razor which states that among competing hypotheses that predict equally well, the one with the fewest assumptions (or variables) should be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Overfitting and Performance with New Datasets\n",
    "\n",
    "Does the adjusted R^2 suggest that we would be overfitting the model by including this variable and thus may have worse performance when prediting `Rate` for *new datasets*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The adjusted $ R^2 $ increases only slightly when adding the `Nudity` variable, indicating it adds minimal explanatory power. Including such variables can increase the risk of overfitting: the model might perform well on the training data but poorly on new data. Thus, based on the small increase in adjusted $ R^2 $, including `Nudity` might lead to overfitting and potentially worse performance on new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Test R^2\n",
    "\n",
    "Calculate the test R^2 of each of these two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004060438212914574"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "predictions_full = model_full.predict(X_test)\n",
    "r2_full_test = r2_score(X_test['Rate'], predictions_full)\n",
    "r2_full_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00016103059717920143"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_reduced = model_reduced.predict(X_test)\n",
    "r2_reduced_test = r2_score(X_test['Rate'], predictions_reduced)\n",
    "r2_reduced_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Test R^2 Corroboration\n",
    "\n",
    "Which model (full vs. reduced) does the test R^2 suggest might perform better when predicting new datasets? Does this suggestion agree with what the adjusted R^2 suggested?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For the full model, the test $ R^2 $ is $ 0.00406 $. This means that only about 0.4% of the variance in the `Rate` in the test set is explained by the full model.\n",
    "2. For the reduced model (without the 'Nudity' variable), the test $ R^2 $ is $ 0.00016 $. This means that only about 0.016% of the variance in the `Rate` in the test set is explained by the reduced model.\n",
    "\n",
    "Given these results:\n",
    "\n",
    "- Both models do not explain much of the variance in the `Rate` in the test dataset. Their predictive power on unseen data (test data) is quite limited.\n",
    "- The full model, while still not particularly strong, does perform better than the reduced model in terms of predictive power on the test data. This suggests that the variable `Nudity` does bring some additional predictive information when combined with the other variables, even though its individual association was found to be the weakest.\n",
    "\n",
    "It's worth noting that while the full model has a slightly better $ R^2 $, the difference is small, and both models have a low $ R^2 $ value, indicating they might not be very useful for prediction on new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. Model Performance\n",
    "\n",
    "Would we expect either of these models to perform *well* when predicting `Rate` for *new datasets*? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No, we wouldn't expect either of these models to perform well on new datasets. The test $ R^2 $ values for both models are extremely low, indicating they explain very little variance in the `Rate` for the test data. Such low predictive power suggests that the models might not generalize effectively to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Total Number of Candidate Models\n",
    "\n",
    "Given that we are considering using the following 5 explanatory variables in our linear regression model (without interaction terms), how many possible linear regression models could we make based on whether we decide to include or exclude each of these 5 variables?\n",
    "\n",
    "* `Nudity`\n",
    "* `Violence`\n",
    "* `Profanity`\n",
    "* `Alcohol`\n",
    "* `Frightening`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_models = 2**5\n",
    "total_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each explanatory variable, you have two choices: \n",
    "\n",
    "1. Include the variable in the model.\n",
    "2. Exclude the variable from the model.\n",
    "\n",
    "So, for each of the 5 variables, there are 2 possible choices. \n",
    "\n",
    "The total number of possible models is:\n",
    "\n",
    "$$\n",
    "2 \\times 2 \\times 2 \\times 2 \\times 2 = 2^5 \n",
    "$$\n",
    "\n",
    "Let's compute this:\n",
    "\n",
    "The total number of possible linear regression models that can be made based on whether we decide to include or exclude each of these 5 variables is $2^5 = 32$.\n",
    "\n",
    "So, there are 32 possible models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Backwards Elimination Algorithm\n",
    "\n",
    "Ideally, we'd like to find the linear regression model that gives us the highest adjusted R^2 value. Use a backwards elimination algorithm to try to find this linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Rate', 'Genre', 'Nudity', 'Violence', 'Profanity', 'Alcohol',\n",
       "       'Frightening', 'is_comedy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03792345158151045"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full = smf.ols(\"Rate ~ C(Nudity) + C(Violence) + C(Profanity) + C(Alcohol) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_full = model_full.rsquared_adj\n",
    "adjusted_r2_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0398088850148931"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NNud= smf.ols(\"Rate ~ + C(Violence) + C(Profanity) + C(Alcohol) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_NNud = model_NNud.rsquared_adj\n",
    "adjusted_r2_NNud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04049272012193206"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NVio = smf.ols(\"Rate ~ C(Nudity) + C(Profanity) + C(Alcohol) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_NVio = model_NVio.rsquared_adj\n",
    "adjusted_r2_NVio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03792345158151045"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NPro = smf.ols(\"Rate ~ C(Nudity) + C(Violence) + C(Profanity) + C(Alcohol) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_NPro = model_NPro.rsquared_adj\n",
    "adjusted_r2_NPro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027424105085708583"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NAlc = smf.ols(\"Rate ~ C(Nudity) + C(Violence) + C(Profanity) + C(Frightening)\", data=X_train).fit()\n",
    "adjusted_r2_NAlc = model_NAlc.rsquared_adj\n",
    "adjusted_r2_NAlc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006672206440563655"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NFri = smf.ols(\"Rate ~ C(Nudity) + C(Violence) + C(Profanity) + C(Alcohol)\", data=X_train).fit()\n",
    "adjusted_r2_NFri = model_NFri.rsquared_adj\n",
    "adjusted_r2_NFri\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interpreting the Backwards Elimination Algorithm Results\n",
    "\n",
    "### 6.1. Best Adjusted R^2 Guarantees\n",
    "\n",
    "Is the final model returned by the backwards elimination algorithm guaranteed to return the linear regression model that has the *highest possible adjusted R^2* out of all possible linear regression models that we could make with our 5 content explanatory variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: No, the final model produced by the backward elimination algorithm is not guaranteed to have the highest possible adjusted $ R^2 $. Here's why:\n",
    "\n",
    "1. **Sequential Nature**: The backward elimination method is sequential, starting with all predictors and removing them one-by-one based on their p-values. The order of removal can influence the outcome, and the final model may not be the optimal one.\n",
    "  \n",
    "2. **Local Optima**: Backward elimination can get trapped in local optima. This means it may find a model that seems best given its current set of variables but isn't the best overall.\n",
    "\n",
    "3. **Collinearity Issues**: If predictors are correlated (collinearity), the p-values can be unreliable. This can mislead the algorithm into removing or retaining certain predictors.\n",
    "\n",
    "4. **Doesn't Examine All Combinations**: The algorithm doesn't assess every possible combination of predictors. It bases decisions on the current model, meaning it might miss a combination with a higher adjusted $ R^2 $.\n",
    "\n",
    "In summary, while backward elimination is a useful heuristic for feature selection, it doesn't guarantee the optimal model in terms of adjusted $ R^2 $. For a definitive answer, one would need to evaluate all potential combinations of predictors, which can be computationally intensive for large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Most Likely Overfitter\n",
    "\n",
    "Of the 5 content explanatory variable that we considered, which one was the most likely to lead to overfitting (if we were to keep all of the other 4 explanatory variables)? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Removing `Nudity`: Increase in adjusted $ R^2 $ from 0.0379 to 0.0398\n",
    "2. Removing `Violence`: Increase in adjusted $ R^2 $ from 0.0379 to 0.0405\n",
    "3. Removing `Profanity`: No change in adjusted $ R^2 $ (it remains 0.0379)\n",
    "4. Removing `Alcohol`: Decrease in adjusted $ R^2 $ from 0.0379 to 0.0274\n",
    "5. Removing `Frightening`: Large decrease in adjusted $ R^2 $ from 0.0379 to 0.0067\n",
    "\n",
    "Based on these changes, the variable `Frightening` shows the most dramatic decrease in adjusted $ R^2 $ when removed. This indicates that it is the most valuable of the variables in explaining the variance in the response, and it is not likely to be the overfitter.\n",
    "\n",
    "On the other hand, the variable `Violence` shows the largest increase in adjusted $ R^2 $ when removed, suggesting it might be the most likely to lead to overfitting when the other four variables are present in the model.\n",
    "\n",
    "Thus, the explanatory variable `Violence` is the most likely to lead to overfitting when considering the other four variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3. Adjusted R^2 Suggestions\n",
    "\n",
    "Let's now consider the adjusted R^2 of 3 candidate models that we've explored in this assignment\n",
    "* the full model (3.1)\n",
    "* the reduced model (3.2)\n",
    "* the final model from the backwards elimination algorithm (5)\n",
    "\n",
    "According to the adjusted R^2, which model is suggested to have the *best* prediction performance for *new datasets*?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Full model (3.1): Adjusted $ R^2 = 0.03792345158151045 $\n",
    "2. Reduced model (3.2): Adjusted $ R^2 = 0.0249 $ (previously mentioned)\n",
    "3. Final model from the backwards elimination algorithm (5): Adjusted $ R^2 = 0.04049272012193206 $ (when removing `Violence`)\n",
    "\n",
    "The final model from the backwards elimination algorithm has the highest adjusted $ R^2 $ value of 0.0405.\n",
    "\n",
    "Thus, according to the adjusted $ R^2 $, the final model from the backwards elimination algorithm is suggested to have the best prediction performance for new datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4. Test R^2\n",
    "\n",
    "Calculate the test R^2 of the final model returned by your backwards elimination algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014104227966577065"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_final = model_NVio.predict(X_test)\n",
    "\n",
    "r2_final_test = r2_score(X_test['Rate'], predictions_final)\n",
    "r2_final_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5. Test R^2 Suggestions\n",
    "\n",
    "Let's now consider the test R^2 of 3 candidate models that we've explored in this assignment\n",
    "* the full model (3.6)\n",
    "* the reduced model (3.6)\n",
    "* the final model from the backwards elimination algorithm (6.3)\n",
    "\n",
    "According to the test R^2, which model is suggested to have the *best* prediction performance for *new datasets*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the provided values:\n",
    "- Full model: $0.0104$ (from section 3.6)\n",
    "- Reduced model: (Assuming it's the same as the full model for now) $0.0104$ (from section 3.6)\n",
    "- Final model from backward elimination: 0.0141 (from section 6.3)\n",
    "\n",
    "The final model from the backward elimination algorithm has the highest test $ R^2 $ score, suggesting it is the best model in terms of prediction performance for new datasets among the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conceptual Question\n",
    "\n",
    "Suppose we wanted to predict `income` given the following two possible explanatory variables:\n",
    "* `college_GPA`\n",
    "* `political_affiliation`: Independent, Republican, Democrat\n",
    "\n",
    "We fit the following three candidate models, each of which had the following training dataset R^2 values.\n",
    "\n",
    "**Full Model (R^2=0.5)**\n",
    "Predicts `income` with:\n",
    "* `college_GPA`\n",
    "* `political_affiliation`: Independent, Republican, Democrat\n",
    "\n",
    "\n",
    "**Reduced Model 1 (R^2=0.43)**\n",
    "Predicts `income` with:\n",
    "* `political_affiliation`: Independent, Republican, Democrat\n",
    "\n",
    "**Reduced Model 2 (R^2=0.43)**\n",
    "Predicts `income` with:\n",
    "* `college_GPA`\n",
    "\n",
    "\n",
    "Will the `Reduced Model 1` or the `Reduced Model 2` have a higher adjusted R^2 value? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "`Reduced Model 2` will have a higher adjusted $ R^2 $ value compared to `Reduced Model 1`. Here's the reasoning:\n",
    "\n",
    "1. **Number of Predictors**: \n",
    "   - `Reduced Model 1` uses the `political_affiliation` variable which, when dummy-coded, results in two predictors (assuming one category like 'Independent' is taken as the reference).\n",
    "   - `Reduced Model 2` has just one predictor, `college_GPA`.\n",
    "\n",
    "2. **Adjusted $ R^2 $ Formula**: The formula for adjusted $ R^2 $ penalizes the inclusion of additional predictors unless they significantly improve the model's fit. Specifically:\n",
    "\n",
    "$$\n",
    "\\text{Adjusted } R^2 = 1 - \\left( \\frac{(1 - R^2)(n-1)}{n-k-1} \\right)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ R^2 $ is the unadjusted coefficient of determination.\n",
    "- $ n $ is the sample size.\n",
    "- $ k $ is the number of predictors.\n",
    "\n",
    "Given that $ R^2 $ is the same for both models and that $ n $ remains constant since both models use the same dataset, the difference in adjusted $ R^2 $ between the two models boils down to the number of predictors, $ k $.\n",
    "\n",
    "3. **Penalty for Additional Predictors**: When $ R^2 $ is constant, an increase in $ k $ results in a decrease in adjusted $ R^2 $. Since `Reduced Model 1` has more predictors than `Reduced Model 2`, its adjusted $ R^2 $ will be lower.\n",
    "\n",
    "In conclusion, given the same $ R^2 $ value but a different number of predictors, `Reduced Model 2` (with fewer predictors) will have a higher adjusted $ R^2 $ value than `Reduced Model 1`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
