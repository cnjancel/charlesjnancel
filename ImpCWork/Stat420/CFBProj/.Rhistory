library(boot)
# Define the number of folds
k <- 10
# Define the statistic to be calculated at each fold
cv_statistic <- function(data, indices) {
indices <- as.integer(indices)
train <- merged_df[indices, ]
test <- merged_df[-indices, ]
# Fit the model to the training set
fit <- lm(final_model, data = train)
# Predict on the test set
predictions <- predict(fit, test)
# Calculate and return the MSE
mean((test$dependent_variable - predictions)^2)
}
# Perform k-fold cross-validation
cv_results <- cv.glm(data = merged_df, glmfit = final_model, K = k, cost = cv_statistic)
# Output the results
print(cv_results$delta)
library(boot)
# Define the number of folds
k <- 10
# Define the statistic to be calculated at each fold
cv_statistic <- function(data, indices) {
indices <- as.integer(indices)
train <- merged_df[indices, ]
test <- merged_df[-indices, ]
# Fit the model to the training set
fit <- lm(final_model, data = train)
# Predict on the test set
predictions <- predict(fit, test)
# Calculate and return the MSE
mean((test$total_wins - predictions)^2)
}
# Perform k-fold cross-validation
cv_results <- cv.glm(data = merged_df, glmfit = final_model, K = k, cost = cv_statistic)
# Output the results
print(cv_results$delta)
t.test(final_model)
# Assume 'total_wins' is your dependent variable and 'game_type' is a binary variable indicating conference (1) or non-conference (0) games.
# Subset your data into two groups
conference_games <- merged_df$total_wins[merged_df$game_type == 1]
non_conference_games <- merged_df$total_wins[merged_df$game_type == 0]
# Perform the t-test
t_test_results <- t.test(conference_games, non_conference_games, alternative = "two.sided", var.equal = TRUE)
# Subset data for conference games and non-conference games
conference_wins <- merged_df$total_wins[merged_df$game_type == 1]
non_conference_wins <- merged_df$total_wins[merged_df$game_type == 0]
# Perform a two-sample t-test
t_test_result <- t.test(conference_wins, non_conference_wins, var.equal = TRUE)
# Check the number of observations for conference games
length(conference_wins) # Should return the count of conference games
# Check the number of observations for non-conference games
length(non_conference_wins) # Should return the count of non-conference games
# Subset data for conference games and non-conference games
conference_wins <- merged_df$total_wins[merged_df$game_type == 1]
non_conference_wins <- merged_df$total_wins[merged_df$game_type == 0]
# Perform a two-sample t-test
t_test_result <- t.test(conference_wins, non_conference_wins, var.equal = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(arrow)
parquet_files <- c(
'Data/cfb_schedules_2001.parquet',
'Data/cfb_schedules_2002.parquet',
'Data/cfb_schedules_2003.parquet',
'Data/cfb_schedules_2004.parquet',
'Data/cfb_schedules_2005.parquet',
'Data/cfb_schedules_2006.parquet',
'Data/cfb_schedules_2007.parquet',
'Data/cfb_schedules_2008.parquet',
'Data/cfb_schedules_2009.parquet',
'Data/cfb_schedules_2010.parquet',
'Data/cfb_schedules_2011.parquet',
'Data/cfb_schedules_2012.parquet',
'Data/cfb_schedules_2013.parquet',
'Data/cfb_schedules_2014.parquet',
'Data/cfb_schedules_2015.parquet',
'Data/cfb_schedules_2016.parquet',
'Data/cfb_schedules_2017.parquet',
'Data/cfb_schedules_2018.parquet',
'Data/cfb_schedules_2019.parquet',
'Data/cfb_schedules_2020.parquet',
'Data/cfb_schedules_2021.parquet',
'Data/cfb_schedules_2022.parquet'
)
# Read the first file as a reference
merged_df <- arrow::read_parquet(parquet_files[1])
# Iterate through the rest of the files and bind them row-wise
for (file in parquet_files[-1]) {
temp_df <- arrow::read_parquet(file)
# Add missing columns with NA values
for (col in setdiff(names(merged_df), names(temp_df))) {
temp_df[[col]] <- NA
}
# Bind rows and retain only the columns present in the reference dataframe
merged_df <- rbind(merged_df, temp_df[, names(merged_df)])
}
library(dplyr)
# Dropping columns with high missingness
merged_df <- dplyr::select(merged_df, -c(start_time_tbd, venue_id, venue))
# Drop 'notes' and 'highlights' columns if they exist
if("notes" %in% colnames(merged_df)) {
merged_df$notes <- NULL
}
if("highlights" %in% colnames(merged_df)) {
merged_df$highlights <- NULL
}
if("season_type" %in% colnames(merged_df)) {
merged_df$season_type <- NULL
}
# Impute missing values for 'conference_game' with the most common value (mode)
common_conference_game <- which.max(table(merged_df$conference_game, useNA = "no"))
merged_df$conference_game[is.na(merged_df$conference_game)] <- common_conference_game == 2
# Imputing missing values for 'home_points' and 'away_points' with their respective medians
merged_df$home_points[is.na(merged_df$home_points)] <- median(merged_df$home_points, na.rm = TRUE)
merged_df$away_points[is.na(merged_df$away_points)] <- median(merged_df$away_points, na.rm = TRUE)
median_attendance <- median(merged_df$attendance, na.rm = TRUE)
merged_df$attendance[is.na(merged_df$attendance)] <- median_attendance
merged_df$excitement_index <- as.numeric(merged_df$excitement_index)
merged_df$away_post_win_prob <- as.numeric(merged_df$away_post_win_prob)
merged_df$home_post_win_prob <- as.numeric(merged_df$home_post_win_prob)
# Impute missing values with median
merged_df$excitement_index[is.na(merged_df$excitement_index)] <- median(merged_df$excitement_index, na.rm = TRUE)
merged_df$away_post_win_prob[is.na(merged_df$away_post_win_prob)] <- median(merged_df$away_post_win_prob, na.rm = TRUE)
merged_df$home_post_win_prob[is.na(merged_df$home_post_win_prob)] <- median(merged_df$home_post_win_prob, na.rm = TRUE)
# Filter out rows with missing ELO ratings
merged_df <- merged_df %>%
filter(!is.na(home_pregame_elo) & !is.na(away_pregame_elo))
merged_df <- merged_df %>%
filter(!is.na(away_postgame_elo) & !is.na(home_postgame_elo))
# Drop rows where specific columns have NA values
merged_df <- merged_df %>% filter(!is.na(home_conference) & !is.na(away_conference))
# Check the dimensions of the dataset after handling missing data
dim(merged_df)
# Check the structure of the modified dataframe
str(merged_df)
# Count NA values in each column
na_counts <- sapply(merged_df, function(x) sum(is.na(x)))
# Print the counts
print(na_counts)
head(merged_df)
arrow::write_parquet(merged_df, "merged_data.parquet")
write.csv(merged_df, "merged_data.csv", row.names = FALSE)
cat("Columns:\n")
print(names(merged_df))
cat("\nSample Data:\n")
print(head(merged_df))
# Calculate home and away wins for each game
merged_df <- merged_df %>%
mutate(home_win = ifelse(home_points > away_points, 1, 0),
away_win = ifelse(away_points > home_points, 1, 0))
# Aggregate total wins for home and away teams separately
home_wins <- merged_df %>%
group_by(season, home_team) %>%
summarise(total_home_wins = sum(home_win), .groups = 'drop')
away_wins <- merged_df %>%
group_by(season, away_team) %>%
summarise(total_away_wins = sum(away_win), .groups = 'drop')
# Resolve many-to-many join issue by ensuring no duplicated rows before joining
home_wins <- home_wins %>% distinct(season, home_team, .keep_all = TRUE)
away_wins <- away_wins %>% distinct(season, away_team, .keep_all = TRUE)
# Join back to the original merged_df to add the total wins for home and away teams
# Here we are assuming that there should be a one-to-one relationship between merged_df
# and the aggregated wins data frames.
merged_df <- merged_df %>%
left_join(home_wins, by = c("season", "home_team")) %>%
left_join(away_wins, by = c("season", "away_team"))
# If you need a single total_wins column per row, you can decide how to handle the games
merged_df <- merged_df %>%
mutate(total_wins = coalesce(total_home_wins, 0) + coalesce(total_away_wins, 0))
# Note: This assumes that for every game, the team will be listed once as a home team and once as an away team.
# If this assumption does not hold true, the logic for creating total_wins needs to be adjusted.
# Identify columns with only one unique value
single_unique_value_cols <- sapply(merged_df, function(x) if(length(unique(x)) == 1) TRUE else FALSE)
# Print the names of columns with only one unique value
names(single_unique_value_cols[single_unique_value_cols == TRUE])
sapply(lapply(merged_df, unique), length)
merged_df$neutral_site <- as.factor(merged_df$neutral_site)
merged_df$conference_game <- as.factor(merged_df$conference_game)
library(ggplot2)
ggplot(merged_df, aes(x = total_wins)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
labs(title = "Histogram of Total Wins", x = "Total Wins", y = "Frequency")
summary(merged_df$total_wins)
sd(merged_df$total_wins, na.rm = TRUE)
library(GGally)
ggpairs(merged_df, columns = c("total_wins", "home_pregame_elo", "away_pregame_elo"))
levels(as.factor(merged_df$conference_game))
levels(as.factor(merged_df$home_conference))
lm_model <- lm(total_wins ~ home_pregame_elo + away_pregame_elo +
as.factor(conference_game) + attendance +
I(week^2),
data = merged_df)
summary(lm_model)
par(mfrow = c(2, 2))
plot(lm_model)
library(car)
vif(lm_model)
single_level_factors <- sapply(merged_df, function(x) if(is.factor(x) && length(levels(x)) == 1) levels(x))
single_level_factors <- single_level_factors[!sapply(single_level_factors, is.null)]
print(single_level_factors)
library(MASS)
# Removing 'season_type' from the model as it has only one level
lm_model_for_boxcox <- lm(total_wins ~ home_pregame_elo + away_pregame_elo +
attendance + I(week^2), data = merged_df)
boxcox_result <- boxcox(lm_model_for_boxcox, plotit = TRUE)
# Determine the optimal lambda value
lambda_optimal <- boxcox_result$x[which.max(boxcox_result$y)]
cat("Optimal lambda for transformation:", lambda_optimal, "\n")
# Apply the Box-Cox transformation with the optimal lambda
merged_df$transformed_total_wins <- ifelse(lambda_optimal == 0,
log(merged_df$total_wins),
(merged_df$total_wins^lambda_optimal - 1) / lambda_optimal)
# Re-fit the model with the transformed response variable
lm_transformed <- lm(transformed_total_wins ~ home_pregame_elo + away_pregame_elo +
attendance + I(week^2), ,
data = merged_df)
summary(lm_transformed)
# Create a new binary variable indicating if the home conference is ACC or SEC
merged_df$is_ACC_or_SEC <- as.factor(merged_df$home_conference %in% c("ACC", "SEC"))
# Now perform the t-test
t_test_result <- t.test(total_wins ~ is_ACC_or_SEC, data = merged_df)
# View the results
print(t_test_result)
library(boot)
# Define the function for k-fold cross-validation
cv_error <- function(data, number_of_folds) {
cv_results <- cv.glm(data, glm(total_wins ~ home_pregame_elo + away_pregame_elo +
as.factor(conference_game) + attendance + I(week^2),
data = data), K = number_of_folds)
return(cv_results$delta)
}
# Perform 10-fold cross-validation
cv_error_result <- cv_error(merged_df, 10)
# Output the cross-validation estimated prediction error
cat("10-fold CV estimated prediction error:", cv_error_result[1], "\n")
# Creating a linear model with an interaction term
interaction_model <- lm(total_wins ~ home_pregame_elo * conference_game +
away_pregame_elo + attendance + I(week^2),
data = merged_df)
# Output the summary of the model
summary(interaction_model)
AIC(lm_model, lm_model_interaction)
# Fit your final selected model
final_model <- lm(total_wins ~ home_pregame_elo * conference_game +
away_pregame_elo + attendance + I(week^2), data = merged_df)
# Display a summary of the final model
summary(final_model)
residuals <- residuals(final_model)
residual_std_dev <- sd(residuals)
cat("Residual Standard Error (Standard Deviation of Residuals):", residual_std_dev, "\n")
vif_results <- vif(final_model, type = "predictor")
cat("Variance Inflation Factors (VIF):\n")
print(vif_results)
# Residual plots to check model assumptions
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
plot(final_model)
# Identify and plot outliers using Cook's distance
cooksd <- cooks.distance(final_model)
plot(cooksd, pch = "18", main = "Cook's Distance Plot")
abline(h = 4/length(cooksd), col = "red")
formula(final_model)
library(boot)
# Define the number of folds
k <- 10
# Define the statistic to be calculated at each fold
cv_statistic <- function(data, indices) {
indices <- as.integer(indices)
train <- merged_df[indices, ]
test <- merged_df[-indices, ]
# Fit the model to the training set
fit <- lm(final_model, data = train)
# Predict on the test set
predictions <- predict(fit, test)
# Calculate and return the MSE
mean((test$total_wins - predictions)^2)
}
# Perform k-fold cross-validation
cv_results <- cv.glm(data = merged_df, glmfit = final_model, K = k, cost = cv_statistic)
# Output the results
print(cv_results$delta)
knitr::opts_chunk$set(echo = TRUE)
library(arrow)
parquet_files <- c(
'Data/cfb_schedules_2001.parquet',
'Data/cfb_schedules_2002.parquet',
'Data/cfb_schedules_2003.parquet',
'Data/cfb_schedules_2004.parquet',
'Data/cfb_schedules_2005.parquet',
'Data/cfb_schedules_2006.parquet',
'Data/cfb_schedules_2007.parquet',
'Data/cfb_schedules_2008.parquet',
'Data/cfb_schedules_2009.parquet',
'Data/cfb_schedules_2010.parquet',
'Data/cfb_schedules_2011.parquet',
'Data/cfb_schedules_2012.parquet',
'Data/cfb_schedules_2013.parquet',
'Data/cfb_schedules_2014.parquet',
'Data/cfb_schedules_2015.parquet',
'Data/cfb_schedules_2016.parquet',
'Data/cfb_schedules_2017.parquet',
'Data/cfb_schedules_2018.parquet',
'Data/cfb_schedules_2019.parquet',
'Data/cfb_schedules_2020.parquet',
'Data/cfb_schedules_2021.parquet',
'Data/cfb_schedules_2022.parquet'
)
# Read the first file as a reference
merged_df <- arrow::read_parquet(parquet_files[1])
# Iterate through the rest of the files and bind them row-wise
for (file in parquet_files[-1]) {
temp_df <- arrow::read_parquet(file)
# Add missing columns with NA values
for (col in setdiff(names(merged_df), names(temp_df))) {
temp_df[[col]] <- NA
}
# Bind rows and retain only the columns present in the reference dataframe
merged_df <- rbind(merged_df, temp_df[, names(merged_df)])
}
library(dplyr)
# Dropping columns with high missingness
merged_df <- dplyr::select(merged_df, -c(start_time_tbd, venue_id, venue))
# Drop 'notes' and 'highlights' columns if they exist
if("notes" %in% colnames(merged_df)) {
merged_df$notes <- NULL
}
if("highlights" %in% colnames(merged_df)) {
merged_df$highlights <- NULL
}
if("season_type" %in% colnames(merged_df)) {
merged_df$season_type <- NULL
}
# Impute missing values for 'conference_game' with the most common value (mode)
common_conference_game <- which.max(table(merged_df$conference_game, useNA = "no"))
merged_df$conference_game[is.na(merged_df$conference_game)] <- common_conference_game == 2
# Imputing missing values for 'home_points' and 'away_points' with their respective medians
merged_df$home_points[is.na(merged_df$home_points)] <- median(merged_df$home_points, na.rm = TRUE)
merged_df$away_points[is.na(merged_df$away_points)] <- median(merged_df$away_points, na.rm = TRUE)
median_attendance <- median(merged_df$attendance, na.rm = TRUE)
merged_df$attendance[is.na(merged_df$attendance)] <- median_attendance
merged_df$excitement_index <- as.numeric(merged_df$excitement_index)
merged_df$away_post_win_prob <- as.numeric(merged_df$away_post_win_prob)
merged_df$home_post_win_prob <- as.numeric(merged_df$home_post_win_prob)
# Impute missing values with median
merged_df$excitement_index[is.na(merged_df$excitement_index)] <- median(merged_df$excitement_index, na.rm = TRUE)
merged_df$away_post_win_prob[is.na(merged_df$away_post_win_prob)] <- median(merged_df$away_post_win_prob, na.rm = TRUE)
merged_df$home_post_win_prob[is.na(merged_df$home_post_win_prob)] <- median(merged_df$home_post_win_prob, na.rm = TRUE)
# Filter out rows with missing ELO ratings
merged_df <- merged_df %>%
filter(!is.na(home_pregame_elo) & !is.na(away_pregame_elo))
merged_df <- merged_df %>%
filter(!is.na(away_postgame_elo) & !is.na(home_postgame_elo))
# Drop rows where specific columns have NA values
merged_df <- merged_df %>% filter(!is.na(home_conference) & !is.na(away_conference))
# Check the dimensions of the dataset after handling missing data
dim(merged_df)
# Check the structure of the modified dataframe
str(merged_df)
# Count NA values in each column
na_counts <- sapply(merged_df, function(x) sum(is.na(x)))
# Print the counts
print(na_counts)
head(merged_df)
arrow::write_parquet(merged_df, "merged_data.parquet")
write.csv(merged_df, "merged_data.csv", row.names = FALSE)
cat("Columns:\n")
print(names(merged_df))
cat("\nSample Data:\n")
print(head(merged_df))
# Calculate home and away wins for each game
merged_df <- merged_df %>%
mutate(home_win = ifelse(home_points > away_points, 1, 0),
away_win = ifelse(away_points > home_points, 1, 0))
# Aggregate total wins for home and away teams separately
home_wins <- merged_df %>%
group_by(season, home_team) %>%
summarise(total_home_wins = sum(home_win), .groups = 'drop')
away_wins <- merged_df %>%
group_by(season, away_team) %>%
summarise(total_away_wins = sum(away_win), .groups = 'drop')
# Resolve many-to-many join issue by ensuring no duplicated rows before joining
home_wins <- home_wins %>% distinct(season, home_team, .keep_all = TRUE)
away_wins <- away_wins %>% distinct(season, away_team, .keep_all = TRUE)
# Join back to the original merged_df to add the total wins for home and away teams
# Here we are assuming that there should be a one-to-one relationship between merged_df
# and the aggregated wins data frames.
merged_df <- merged_df %>%
left_join(home_wins, by = c("season", "home_team")) %>%
left_join(away_wins, by = c("season", "away_team"))
# If you need a single total_wins column per row, you can decide how to handle the games
merged_df <- merged_df %>%
mutate(total_wins = coalesce(total_home_wins, 0) + coalesce(total_away_wins, 0))
# Note: This assumes that for every game, the team will be listed once as a home team and once as an away team.
# If this assumption does not hold true, the logic for creating total_wins needs to be adjusted.
# Identify columns with only one unique value
single_unique_value_cols <- sapply(merged_df, function(x) if(length(unique(x)) == 1) TRUE else FALSE)
# Print the names of columns with only one unique value
names(single_unique_value_cols[single_unique_value_cols == TRUE])
sapply(lapply(merged_df, unique), length)
merged_df$neutral_site <- as.factor(merged_df$neutral_site)
merged_df$conference_game <- as.factor(merged_df$conference_game)
library(ggplot2)
ggplot(merged_df, aes(x = total_wins)) +
geom_histogram(bins = 30, fill = "blue", color = "black") +
labs(title = "Histogram of Total Wins", x = "Total Wins", y = "Frequency")
summary(merged_df$total_wins)
sd(merged_df$total_wins, na.rm = TRUE)
library(GGally)
ggpairs(merged_df, columns = c("total_wins", "home_pregame_elo", "away_pregame_elo"))
levels(as.factor(merged_df$conference_game))
levels(as.factor(merged_df$home_conference))
lm_model <- lm(total_wins ~ home_pregame_elo + away_pregame_elo +
as.factor(conference_game) + attendance +
I(week^2),
data = merged_df)
summary(lm_model)
par(mfrow = c(2, 2))
plot(lm_model)
library(car)
vif(lm_model)
single_level_factors <- sapply(merged_df, function(x) if(is.factor(x) && length(levels(x)) == 1) levels(x))
single_level_factors <- single_level_factors[!sapply(single_level_factors, is.null)]
print(single_level_factors)
library(MASS)
# Removing 'season_type' from the model as it has only one level
lm_model_for_boxcox <- lm(total_wins ~ home_pregame_elo + away_pregame_elo +
attendance + I(week^2), data = merged_df)
boxcox_result <- boxcox(lm_model_for_boxcox, plotit = TRUE)
# Determine the optimal lambda value
lambda_optimal <- boxcox_result$x[which.max(boxcox_result$y)]
cat("Optimal lambda for transformation:", lambda_optimal, "\n")
# Apply the Box-Cox transformation with the optimal lambda
merged_df$transformed_total_wins <- ifelse(lambda_optimal == 0,
log(merged_df$total_wins),
(merged_df$total_wins^lambda_optimal - 1) / lambda_optimal)
# Re-fit the model with the transformed response variable
lm_transformed <- lm(transformed_total_wins ~ home_pregame_elo + away_pregame_elo +
attendance + I(week^2), ,
data = merged_df)
summary(lm_transformed)
# Create a new binary variable indicating if the home conference is ACC or SEC
merged_df$is_ACC_or_SEC <- as.factor(merged_df$home_conference %in% c("ACC", "SEC"))
# Now perform the t-test
t_test_result <- t.test(total_wins ~ is_ACC_or_SEC, data = merged_df)
# View the results
print(t_test_result)
library(boot)
# Define the function for k-fold cross-validation
cv_error <- function(data, number_of_folds) {
cv_results <- cv.glm(data, glm(total_wins ~ home_pregame_elo + away_pregame_elo +
as.factor(conference_game) + attendance + I(week^2),
data = data), K = number_of_folds)
return(cv_results$delta)
}
# Perform 10-fold cross-validation
cv_error_result <- cv_error(merged_df, 10)
# Output the cross-validation estimated prediction error
cat("10-fold CV estimated prediction error:", cv_error_result[1], "\n")
# Creating a linear model with an interaction term
lm_model_interaction <- lm(total_wins ~ home_pregame_elo * conference_game +
away_pregame_elo + attendance + I(week^2),
data = merged_df)
# Output the summary of the model
summary(lm_model_interaction)
AIC(lm_model, lm_model_interaction)
# Fit your final selected model
final_model <- lm(total_wins ~ home_pregame_elo * conference_game +
away_pregame_elo + attendance + I(week^2), data = merged_df)
# Display a summary of the final model
summary(final_model)
residuals <- residuals(final_model)
residual_std_dev <- sd(residuals)
cat("Residual Standard Error (Standard Deviation of Residuals):", residual_std_dev, "\n")
vif_results <- vif(final_model, type = "predictor")
cat("Variance Inflation Factors (VIF):\n")
print(vif_results)
# Residual plots to check model assumptions
par(mfrow = c(2, 2))  # Arrange plots in a 2x2 grid
plot(final_model)
# Identify and plot outliers using Cook's distance
cooksd <- cooks.distance(final_model)
plot(cooksd, pch = "18", main = "Cook's Distance Plot")
abline(h = 4/length(cooksd), col = "red")
formula(final_model)
library(boot)
# Define the number of folds
k <- 10
# Define the statistic to be calculated at each fold
cv_statistic <- function(data, indices) {
indices <- as.integer(indices)
train <- merged_df[indices, ]
test <- merged_df[-indices, ]
# Fit the model to the training set
fit <- lm(final_model, data = train)
# Predict on the test set
predictions <- predict(fit, test)
# Calculate and return the MSE
mean((test$total_wins - predictions)^2)
}
# Perform k-fold cross-validation
cv_results <- cv.glm(data = merged_df, glmfit = final_model, K = k, cost = cv_statistic)
# Output the results
print(cv_results$delta)
# Convert conference_game to binary numeric variable
merged_df$conference_game_numeric <- as.numeric(merged_df$conference_game) - 1
# Subset data
conference_wins <- merged_df$total_wins[merged_df$conference_game_numeric == 1]
non_conference_wins <- merged_df$total_wins[merged_df$conference_game_numeric == 0]
# Perform the t-test
t_test_results <- t.test(conference_wins, non_conference_wins)
# Print the results
print(t_test_results)
