# For a more detailed analysis, you could combine these to see which points have both
which(high_leverage & large_std_residuals)
# Exclude influential points based on their indices
non_influential_data <- races.table[-c(7, 11, 35), ]
# Refit the model without the influential points
model_without_influentials <- lm(Time ~ Distance + Climb + Distance:Climb, data=non_influential_data)
# Print the coefficients of the new model
coef(model_without_influentials)
# Calculate fitted values for the original model
fitted_values_original <- predict(model, newdata = races.table)
# Calculate fitted values for the model without influential points
fitted_values_new <- predict(model_without_influentials, newdata = races.table)
# Create a dataframe with both sets of fitted values
fitted_values_df <- data.frame(FittedOriginal = fitted_values_original, FittedNew = fitted_values_new)
# Create a scatterplot of the fitted values
library(ggplot2)
ggplot(fitted_values_df, aes(x = FittedOriginal, y = FittedNew)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
xlab("Fitted Values from Original Model") +
ylab("Fitted Values from New Model") +
ggtitle("Comparison of Fitted Values: Original vs. New Model") +
theme_minimal()
library(readr)
# Read in the hospital data
hospital_data <- read_csv("hospital.csv")
# Fit the linear model
model <- lm(Charges ~ EdYears + Pressure + Age, data=hospital_data)
# Output the summary of the model
summary(model)
# Calculate leverages
leverages <- hatvalues(model)
# Define the course threshold for high leverage
course_threshold <- 2 * (length(coefficients(model)) + 1) / nrow(hospital_data)
# Count observations with high leverage
high_leverage_count <- sum(leverages > course_threshold)
# Create a histogram of leverages
hist(leverages, breaks = 30, main = "Histogram of Leverages", xlab = "Leverage Values")
# Add a vertical line for the course threshold
abline(v = course_threshold, col = "red", lwd = 2)
# Output the count of high leverage observations
high_leverage_count
# Calculate standardized residuals
standardized_residuals <- rstandard(model)
# Adjust the value as per your course definition
threshold_high_residual <- 2
# Count observations with high standardized residuals
high_residual_count <- sum(abs(standardized_residuals) > threshold_high_residual)
# Create a histogram of standardized residuals
hist(standardized_residuals, breaks = 30, main = "Histogram of Standardized Residuals", xlab = "Standardized Residuals")
# Output the count of high standardized residuals
high_residual_count
# Calculate Cook's distance for each observation
cooks_distances <- cooks.distance(model)
# Define the threshold for identifying influential observations
# Using the conservative threshold 4/(n-k-1)
n <- nrow(hospital_data)
k <- length(coefficients(model)) - 1
threshold_cooks <- 4 / (n - k - 1)
# Identify observations with Cook's distance above the threshold
influential_obs <- which(cooks_distances > threshold_cooks)
# Print the influential observations based on Cook's distance
influential_obs
# Cook's distances for the influential observations
cooks_distances[influential_obs]
# Generate default diagnostic plots
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
plot(model)
# Load the necessary library
library(boot)
# Define the model formula
formula <- Charges ~ EdYears + Pressure + Age
# Define a function for LOOCV
loocv_rmse <- function(formula, data) {
# Perform LOOCV
loocv <- cv.glm(data, glm(formula, data=data), K=nrow(data))
# Return the RMSE
sqrt(loocv$delta[1])
}
# Calculate RMSE using LOOCV
rmse_value <- loocv_rmse(formula, hospital_data)
# Print the RMSE
rmse_value
# Regress Days on the other independent variables
model_collinearity <- lm(Days ~ EdYears + Pressure + Age, data = hospital_data)
# Calculate the R^2 measure of collinearity
rsq_collinearity <- summary(model_collinearity)$r.squared
# Print the R^2 value
rsq_collinearity
# Step 1: Fit the original model (from Question 3)
model_original <- lm(Charges ~ EdYears + Pressure + Age, data = hospital_data)
# Step 2: Fit the model for Days
model_days <- lm(Days ~ EdYears + Pressure + Age, data = hospital_data)
resid_days <- residuals(model_days)
# Step 3: Fit the model for Charges with Days as the predictor
model_charges_days <- lm(Charges ~ Days, data = hospital_data)
resid_charges <- residuals(model_charges_days)
# Step 4: Calculate the partial correlation coefficient
partial_correlation <- cor(resid_days, resid_charges)
# Step 5: Create the variable added plot
plot(resid_days, resid_charges,
xlab = "Residuals of Days (after accounting for EdYears, Pressure, and Age)",
ylab = "Residuals of Charges (after accounting for Days)",
main = "Variable Added Plot for Days")
# Add a regression line
abline(lm(resid_charges ~ resid_days), col = "red")
# Print the partial correlation coefficient
partial_correlation
# Fit the linear model to the variable added plot
model_va <- lm(resid_charges ~ resid_days)
# Get the summary of the model
summary_va <- summary(model_va)
# Print the summary to check the slope significance
summary_va
# Fit the model with the Days variable
model_with_days <- lm(Charges ~ EdYears + Pressure + Age + Days, data = hospital_data)
# Run the ANOVA test to compare the two models
anova_test <- anova(model_original, model_with_days)
# Print the ANOVA table
anova_test
install.packages("car")
# Load the car package to use the vif function
library(car)
install.packages("car")
install.packages("car")
install.packages("car")
# Load the car package to use the vif function
library(car)
# Calculate VIFs for the model with Days
vif_model_with_days <- vif(model_with_days)
# Print the VIFs
vif_model_with_days
library(ggplot2)
library(faraway)
library(ISLR)
url = 'http://www.statsci.org/data/general/hills.txt'
races.table = read.table(url, header=TRUE, sep='\t')
races.table[18,4] = 18.65
races.table$Climb = races.table$Climb / 1000
head(races.table)
library(GGally)
# Create a scatterplot matrix of the quantitative variables in races.table
ggpairs(races.table[, sapply(races.table, is.numeric)])
# Fit a multiple regression model
model <- lm(Time ~ Distance + Climb + Distance:Climb, data=races.table)
# Get the summary of the model
model_summary <- summary(model)
# Output the summary
model_summary
# Coefficients from the model
coeff_distance <- 4.9290
coeff_distance_climb <- 0.6731
# Calculate the slope for Distance when Climb is 0.3
slope_distance_at_climb_0_3 <- coeff_distance + (coeff_distance_climb * 0.3)
# Calculate the slope for Distance when Climb is 3
slope_distance_at_climb_3 <- coeff_distance + (coeff_distance_climb * 3)
# Output the slopes
slope_distance_at_climb_0_3
slope_distance_at_climb_3
# Calculate influence measures
influence_measures <- influence.measures(model)
# Extract the hat values (leverage)
hat_values <- influence_measures$hat
# Extract the standardized residuals
standardized_residuals <- rstandard(model)
# Determine high leverage points
high_leverage <- hat_values > (2 * ((length(coefficients(model)) + 1) / length(fitted(model))))
# Determine observations with large standardized residuals
large_std_residuals <- abs(standardized_residuals) > 2
# Output influential points based on high leverage
which(high_leverage)
# Output influential points based on large standardized residuals
which(large_std_residuals)
# For a more detailed analysis, you could combine these to see which points have both
which(high_leverage & large_std_residuals)
# Exclude influential points based on their indices
non_influential_data <- races.table[-c(7, 11, 35), ]
# Refit the model without the influential points
model_without_influentials <- lm(Time ~ Distance + Climb + Distance:Climb, data=non_influential_data)
# Print the coefficients of the new model
coef(model_without_influentials)
# Calculate fitted values for the original model
fitted_values_original <- predict(model, newdata = races.table)
# Calculate fitted values for the model without influential points
fitted_values_new <- predict(model_without_influentials, newdata = races.table)
# Create a dataframe with both sets of fitted values
fitted_values_df <- data.frame(FittedOriginal = fitted_values_original, FittedNew = fitted_values_new)
# Create a scatterplot of the fitted values
library(ggplot2)
ggplot(fitted_values_df, aes(x = FittedOriginal, y = FittedNew)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
xlab("Fitted Values from Original Model") +
ylab("Fitted Values from New Model") +
ggtitle("Comparison of Fitted Values: Original vs. New Model") +
theme_minimal()
library(readr)
# Read in the hospital data
hospital_data <- read_csv("hospital.csv")
# Fit the linear model
model <- lm(Charges ~ EdYears + Pressure + Age, data=hospital_data)
# Output the summary of the model
summary(model)
# Calculate leverages
leverages <- hatvalues(model)
# Define the course threshold for high leverage
course_threshold <- 2 * (length(coefficients(model)) + 1) / nrow(hospital_data)
# Count observations with high leverage
high_leverage_count <- sum(leverages > course_threshold)
# Create a histogram of leverages
hist(leverages, breaks = 30, main = "Histogram of Leverages", xlab = "Leverage Values")
# Add a vertical line for the course threshold
abline(v = course_threshold, col = "red", lwd = 2)
# Output the count of high leverage observations
high_leverage_count
# Calculate standardized residuals
standardized_residuals <- rstandard(model)
# Adjust the value as per your course definition
threshold_high_residual <- 2
# Count observations with high standardized residuals
high_residual_count <- sum(abs(standardized_residuals) > threshold_high_residual)
# Create a histogram of standardized residuals
hist(standardized_residuals, breaks = 30, main = "Histogram of Standardized Residuals", xlab = "Standardized Residuals")
# Output the count of high standardized residuals
high_residual_count
# Calculate Cook's distance for each observation
cooks_distances <- cooks.distance(model)
# Define the threshold for identifying influential observations
# Using the conservative threshold 4/(n-k-1)
n <- nrow(hospital_data)
k <- length(coefficients(model)) - 1
threshold_cooks <- 4 / (n - k - 1)
# Identify observations with Cook's distance above the threshold
influential_obs <- which(cooks_distances > threshold_cooks)
# Print the influential observations based on Cook's distance
influential_obs
# Cook's distances for the influential observations
cooks_distances[influential_obs]
# Generate default diagnostic plots
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
plot(model)
# Load the necessary library
library(boot)
# Define the model formula
formula <- Charges ~ EdYears + Pressure + Age
# Define a function for LOOCV
loocv_rmse <- function(formula, data) {
# Perform LOOCV
loocv <- cv.glm(data, glm(formula, data=data), K=nrow(data))
# Return the RMSE
sqrt(loocv$delta[1])
}
# Calculate RMSE using LOOCV
rmse_value <- loocv_rmse(formula, hospital_data)
# Print the RMSE
rmse_value
# Regress Days on the other independent variables
model_collinearity <- lm(Days ~ EdYears + Pressure + Age, data = hospital_data)
# Calculate the R^2 measure of collinearity
rsq_collinearity <- summary(model_collinearity)$r.squared
# Print the R^2 value
rsq_collinearity
# Step 1: Fit the original model (from Question 3)
model_original <- lm(Charges ~ EdYears + Pressure + Age, data = hospital_data)
# Step 2: Fit the model for Days
model_days <- lm(Days ~ EdYears + Pressure + Age, data = hospital_data)
resid_days <- residuals(model_days)
# Step 3: Fit the model for Charges with Days as the predictor
model_charges_days <- lm(Charges ~ Days, data = hospital_data)
resid_charges <- residuals(model_charges_days)
# Step 4: Calculate the partial correlation coefficient
partial_correlation <- cor(resid_days, resid_charges)
# Step 5: Create the variable added plot
plot(resid_days, resid_charges,
xlab = "Residuals of Days (after accounting for EdYears, Pressure, and Age)",
ylab = "Residuals of Charges (after accounting for Days)",
main = "Variable Added Plot for Days")
# Add a regression line
abline(lm(resid_charges ~ resid_days), col = "red")
# Print the partial correlation coefficient
partial_correlation
# Fit the linear model to the variable added plot
model_va <- lm(resid_charges ~ resid_days)
# Get the summary of the model
summary_va <- summary(model_va)
# Print the summary to check the slope significance
summary_va
# Fit the model with the Days variable
model_with_days <- lm(Charges ~ EdYears + Pressure + Age + Days, data = hospital_data)
# Run the ANOVA test to compare the two models
anova_test <- anova(model_original, model_with_days)
# Print the ANOVA table
anova_test
# Load the car package to use the vif function
library(car)
# Calculate VIFs for the model with Days
vif_model_with_days <- vif(model_with_days)
# Print the VIFs
vif_model_with_days
data(Credit)
Credit = subset(Credit, select = -c(ID))
# Create a full model with all predictors
full_model <- lm(Balance ~ ., data = Credit)
# Calculate Variance Inflation Factors (VIF) for the predictors
library(car)
vif(full_model)
# Identify collinearity and run models with one of the collinear predictors removed
# You will need to look at the VIF values to identify which predictors are collinear.
# For example, if 'Income' and 'Limit' are collinear, you would run:
model_without_Income <- lm(Balance ~ . -Income, data = Credit)
model_without_Limit <- lm(Balance ~ . -Limit, data = Credit)
# Compare R-squared values to decide which predictor to drop
summary(model_without_Income)$r.squared
summary(model_without_Limit)$r.squared
# Calculate R-squared measure of collinearity from VIFs
# And by fitting more models if needed
# Assuming 'Income' was dropped based on the previous step
Income_vif <- vif(model_without_Income)["Income"]
Income_R2_collinearity <- 1 - 1/Income_vif
# Fit two more models to calculate R-squared measure of collinearity for 'Income'
model_predict_Income <- lm(Income ~ . -Balance, data = Credit)
summary(model_predict_Income)$r.squared```
library(ggplot2)
library(faraway)
library(ISLR)
url = 'http://www.statsci.org/data/general/hills.txt'
races.table = read.table(url, header=TRUE, sep='\t')
races.table[18,4] = 18.65
races.table$Climb = races.table$Climb / 1000
head(races.table)
library(GGally)
# Create a scatterplot matrix of the quantitative variables in races.table
ggpairs(races.table[, sapply(races.table, is.numeric)])
# Fit a multiple regression model
model <- lm(Time ~ Distance + Climb + Distance:Climb, data=races.table)
# Get the summary of the model
model_summary <- summary(model)
# Output the summary
model_summary
# Coefficients from the model
coeff_distance <- 4.9290
coeff_distance_climb <- 0.6731
# Calculate the slope for Distance when Climb is 0.3
slope_distance_at_climb_0_3 <- coeff_distance + (coeff_distance_climb * 0.3)
# Calculate the slope for Distance when Climb is 3
slope_distance_at_climb_3 <- coeff_distance + (coeff_distance_climb * 3)
# Output the slopes
slope_distance_at_climb_0_3
slope_distance_at_climb_3
# Calculate influence measures
influence_measures <- influence.measures(model)
# Extract the hat values (leverage)
hat_values <- influence_measures$hat
# Extract the standardized residuals
standardized_residuals <- rstandard(model)
# Determine high leverage points
high_leverage <- hat_values > (2 * ((length(coefficients(model)) + 1) / length(fitted(model))))
# Determine observations with large standardized residuals
large_std_residuals <- abs(standardized_residuals) > 2
# Output influential points based on high leverage
which(high_leverage)
# Output influential points based on large standardized residuals
which(large_std_residuals)
# For a more detailed analysis, you could combine these to see which points have both
which(high_leverage & large_std_residuals)
# Exclude influential points based on their indices
non_influential_data <- races.table[-c(7, 11, 35), ]
# Refit the model without the influential points
model_without_influentials <- lm(Time ~ Distance + Climb + Distance:Climb, data=non_influential_data)
# Print the coefficients of the new model
coef(model_without_influentials)
# Calculate fitted values for the original model
fitted_values_original <- predict(model, newdata = races.table)
# Calculate fitted values for the model without influential points
fitted_values_new <- predict(model_without_influentials, newdata = races.table)
# Create a dataframe with both sets of fitted values
fitted_values_df <- data.frame(FittedOriginal = fitted_values_original, FittedNew = fitted_values_new)
# Create a scatterplot of the fitted values
library(ggplot2)
ggplot(fitted_values_df, aes(x = FittedOriginal, y = FittedNew)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
xlab("Fitted Values from Original Model") +
ylab("Fitted Values from New Model") +
ggtitle("Comparison of Fitted Values: Original vs. New Model") +
theme_minimal()
library(readr)
# Read in the hospital data
hospital_data <- read_csv("hospital.csv")
# Fit the linear model
model <- lm(Charges ~ EdYears + Pressure + Age, data=hospital_data)
# Output the summary of the model
summary(model)
# Calculate leverages
leverages <- hatvalues(model)
# Define the course threshold for high leverage
course_threshold <- 2 * (length(coefficients(model)) + 1) / nrow(hospital_data)
# Count observations with high leverage
high_leverage_count <- sum(leverages > course_threshold)
# Create a histogram of leverages
hist(leverages, breaks = 30, main = "Histogram of Leverages", xlab = "Leverage Values")
# Add a vertical line for the course threshold
abline(v = course_threshold, col = "red", lwd = 2)
# Output the count of high leverage observations
high_leverage_count
# Calculate standardized residuals
standardized_residuals <- rstandard(model)
# Adjust the value as per your course definition
threshold_high_residual <- 2
# Count observations with high standardized residuals
high_residual_count <- sum(abs(standardized_residuals) > threshold_high_residual)
# Create a histogram of standardized residuals
hist(standardized_residuals, breaks = 30, main = "Histogram of Standardized Residuals", xlab = "Standardized Residuals")
# Output the count of high standardized residuals
high_residual_count
# Calculate Cook's distance for each observation
cooks_distances <- cooks.distance(model)
# Define the threshold for identifying influential observations
# Using the conservative threshold 4/(n-k-1)
n <- nrow(hospital_data)
k <- length(coefficients(model)) - 1
threshold_cooks <- 4 / (n - k - 1)
# Identify observations with Cook's distance above the threshold
influential_obs <- which(cooks_distances > threshold_cooks)
# Print the influential observations based on Cook's distance
influential_obs
# Cook's distances for the influential observations
cooks_distances[influential_obs]
# Generate default diagnostic plots
par(mfrow=c(2,2))  # Arrange plots in 2x2 grid
plot(model)
# Load the necessary library
library(boot)
# Define the model formula
formula <- Charges ~ EdYears + Pressure + Age
# Define a function for LOOCV
loocv_rmse <- function(formula, data) {
# Perform LOOCV
loocv <- cv.glm(data, glm(formula, data=data), K=nrow(data))
# Return the RMSE
sqrt(loocv$delta[1])
}
# Calculate RMSE using LOOCV
rmse_value <- loocv_rmse(formula, hospital_data)
# Print the RMSE
rmse_value
# Regress Days on the other independent variables
model_collinearity <- lm(Days ~ EdYears + Pressure + Age, data = hospital_data)
# Calculate the R^2 measure of collinearity
rsq_collinearity <- summary(model_collinearity)$r.squared
# Print the R^2 value
rsq_collinearity
# Step 1: Fit the original model (from Question 3)
model_original <- lm(Charges ~ EdYears + Pressure + Age, data = hospital_data)
# Step 2: Fit the model for Days
model_days <- lm(Days ~ EdYears + Pressure + Age, data = hospital_data)
resid_days <- residuals(model_days)
# Step 3: Fit the model for Charges with Days as the predictor
model_charges_days <- lm(Charges ~ Days, data = hospital_data)
resid_charges <- residuals(model_charges_days)
# Step 4: Calculate the partial correlation coefficient
partial_correlation <- cor(resid_days, resid_charges)
# Step 5: Create the variable added plot
plot(resid_days, resid_charges,
xlab = "Residuals of Days (after accounting for EdYears, Pressure, and Age)",
ylab = "Residuals of Charges (after accounting for Days)",
main = "Variable Added Plot for Days")
# Add a regression line
abline(lm(resid_charges ~ resid_days), col = "red")
# Print the partial correlation coefficient
partial_correlation
# Fit the linear model to the variable added plot
model_va <- lm(resid_charges ~ resid_days)
# Get the summary of the model
summary_va <- summary(model_va)
# Print the summary to check the slope significance
summary_va
# Fit the model with the Days variable
model_with_days <- lm(Charges ~ EdYears + Pressure + Age + Days, data = hospital_data)
# Run the ANOVA test to compare the two models
anova_test <- anova(model_original, model_with_days)
# Print the ANOVA table
anova_test
# Load the car package to use the vif function
library(car)
# Calculate VIFs for the model with Days
vif_model_with_days <- vif(model_with_days)
# Print the VIFs
vif_model_with_days
data(Credit)
Credit = subset(Credit, select = -c(ID))
# Create a full model with all predictors
full_model <- lm(Balance ~ ., data = Credit)
# Calculate Variance Inflation Factors (VIF) for the predictors
library(car)
vif(full_model)
# Identify collinearity and run models with one of the collinear predictors removed
# You will need to look at the VIF values to identify which predictors are collinear.
# For example, if 'Income' and 'Limit' are collinear, you would run:
model_without_Income <- lm(Balance ~ . -Income, data = Credit)
model_without_Limit <- lm(Balance ~ . -Limit, data = Credit)
# Compare R-squared values to decide which predictor to drop
summary(model_without_Income)$r.squared
summary(model_without_Limit)$r.squared
# Calculate R-squared measure of collinearity from VIFs
# And by fitting more models if needed
# Assuming 'Income' was dropped based on the previous step
Income_vif <- vif(model_without_Income)["Income"]
Income_R2_collinearity <- 1 - 1/Income_vif
# Fit two more models to calculate R-squared measure of collinearity for 'Income'
model_predict_Income <- lm(Income ~ . -Balance, data = Credit)
summary(model_predict_Income)$r.squared
