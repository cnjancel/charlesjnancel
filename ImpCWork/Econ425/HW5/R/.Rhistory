nonsignificant_vars <- !significant_vars  # Adjusted for correct indices
non_sig_formula <- reformulate(names(nonsignificant_vars)[nonsignificant_vars], response = "wage")
# Restricted model with non-significant variables
model_restricted <- lm(non_sig_formula, data = nba_2)
# Joint hypothesis test using anova
anova_results <- anova(model_restricted, model_full)
f_statistic <- anova_results$`F`[2]  # F statistic for the full model component
# Print the F statistic rounded to three decimal places
print(paste("F-statistic:", round(f_statistic, 3)))
# Combine the datasets
combined_nba <- rbind(nba_1, nba_2)
# Calculate minutes per game
combined_nba$minutes_per_game <- combined_nba$minutes / combined_nba$games
# Calculate the mean of minutes per game
mean_minutes_per_game <- mean(combined_nba$minutes_per_game, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean
print(paste("Mean minutes per game:", round(mean_minutes_per_game, 2)))
# Filter for players in their seventh year
seventh_year_players <- combined_nba[combined_nba$exper == 7, ]
# Calculate the mean wage for these players
mean_wage_seventh_year <- mean(seventh_year_players$wage, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean wage
print(round(mean_wage_seventh_year, 2)*1000)
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(stats)
library(Metrics)
nba_1 <- read_csv("/Users/cancel/Personal/Coursework/Econ203/HW11/nba_1-1.csv")
nba_2 <- read_csv("/Users/cancel/Personal/Coursework/Econ203/HW11/nba_2.csv")
# Count the number of guards, forwards, and centers
guard_count <- sum(nba_1$guard)
forward_count <- sum(nba_1$forward)
center_count <- nrow(nba_1) - (guard_count + forward_count)
print(paste("Guards:", guard_count))
print(paste("Forwards:", forward_count))
print(paste("Centers:", center_count))
highest_wage <- max(nba_1$wage)
print(highest_wage*1000)
model <- lm(wage ~ exper + age + coll + points + allstar, data = nba_1)
summary_model <- summary(model)
print(summary_model)
insignificant_vars <- summary_model$coefficients[, 4] > 0.1
num_insignificant_vars <- sum(insignificant_vars)
print(paste("Number of insignificant variables at 10% level:", num_insignificant_vars))
exper_pvalue <- summary_model$coefficients["exper", "Pr(>|t|)"]
significance_levels <- c(0.001, 0.01, 0.05, 0.1, 0.2)
rejected_levels <- significance_levels[significance_levels > exper_pvalue]
print(paste("The null hypothesis that the coefficient for experience is equal to 0 can be rejected at these significance levels:", paste(rejected_levels * 100, "%", sep = "")))
predictions <- predict(model)
n <- nrow(nba_1)  # Number of observations
manual_mse <- sum((nba_1$wage - predictions)^2) / n  # MSE calculation
# Calculate MSE using Metrics package
metrics_mse <- mse(nba_1$wage, predictions)
print(paste("Manual MSE calculation:", round(manual_mse)))
print(paste("Metrics package MSE:", round(metrics_mse)))
adjusted_r_squared <- summary_model$adj.r.squared
f_statistic <- summary_model$fstatistic[1]
print(paste("Adjusted R-squared:", round(adjusted_r_squared, 2)))
print(paste("F-statistic:", round(f_statistic, 2)))
proportion_eighth_year_or_more <- mean(nba_2$exper >= 8)
rounded_proportion <- round(proportion_eighth_year_or_more, 4)
print(rounded_proportion)
eighth_year_players <- nba_2[nba_2$exper >= 8, ]
probability_million_wage <- mean(eighth_year_players$wage >= 1000)
# Round the result to four decimal places
rounded_probability <- round(probability_million_wage, 4)
# Print the result
print(rounded_probability)
# Ensuring it has the same structure expected by the model
X_new <- with(nba_2, data.frame(exper = exper, age = age, coll = coll, points = points, allstar = allstar))
predicted_wages <- predict(model, newdata = X_new)
n <- nrow(nba_2)  # Number of observations
manual_mse <- sum((nba_2$wage - predicted_wages)^2) / n  # MSE calculation
# Calculate MSE using Metrics package
metrics_mse <- mse(nba_2$wage, predicted_wages)
print(paste("Manual MSE calculation:", round(manual_mse)))
print(paste("Metrics package MSE:", round(metrics_mse)))
# First regression: all predictors
model_full <- lm(wage ~ exper + age + coll + points + allstar, data = nba_2)
summary_model_full <- summary(model_full)
# Identify significant variables at the 5% level
significant_vars <- summary_model_full$coefficients[-1, 4] <= 0.05  # Exclude the intercept
significant_var_names <- names(significant_vars)[significant_vars]
# Ensure to include 'wage' in the subset for the model
significant_var_names <- c("wage", significant_var_names)
# Fit a model using only significant variables
significant_model <- lm(wage ~ ., data = nba_2[, significant_var_names])
# Print summary of the significant model
print(summary(significant_model))
# Non-significant variables for joint hypothesis test
nonsignificant_vars <- !significant_vars  # Adjusted for correct indices
non_sig_formula <- reformulate(names(nonsignificant_vars)[nonsignificant_vars], response = "wage")
# Restricted model with non-significant variables
model_restricted <- lm(non_sig_formula, data = nba_2)
# Joint hypothesis test using anova
anova_results <- anova(model_restricted, model_full)
f_statistic <- anova_results$`F`[2]  # F statistic for the full model component
# Print the F statistic rounded to three decimal places
print(paste("F-statistic:", round(f_statistic, 3)))
# Combine the datasets
combined_nba <- rbind(nba_1, nba_2)
# Calculate minutes per game
combined_nba$minutes_per_game <- combined_nba$minutes / combined_nba$games
# Calculate the mean of minutes per game
mean_minutes_per_game <- mean(combined_nba$minutes_per_game, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean
print(paste("Mean minutes per game:", round(mean_minutes_per_game, 2)))
# Filter for players in their seventh year
seventh_year_players <- combined_nba[combined_nba$exper == 7, ]
# Calculate the mean wage for these players
mean_wage_seventh_year <- mean(seventh_year_players$wage, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean wage
print(paste("Mean seventh year wage: ", round(mean_wage_seventh_year, 2)*1000))
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(stats)
library(Metrics)
nba_1 <- read_csv("/Users/cancel/Personal/Coursework/Econ203/HW11/nba_1-1.csv")
nba_2 <- read_csv("/Users/cancel/Personal/Coursework/Econ203/HW11/nba_2.csv")
# Count the number of guards, forwards, and centers
guard_count <- sum(nba_1$guard)
forward_count <- sum(nba_1$forward)
center_count <- nrow(nba_1) - (guard_count + forward_count)
print(paste("Guards:", guard_count))
print(paste("Forwards:", forward_count))
print(paste("Centers:", center_count))
highest_wage <- max(nba_1$wage)
print(highest_wage*1000)
model <- lm(wage ~ exper + age + coll + points + allstar, data = nba_1)
summary_model <- summary(model)
print(summary_model)
insignificant_vars <- summary_model$coefficients[, 4] > 0.1
num_insignificant_vars <- sum(insignificant_vars)
print(paste("Number of insignificant variables at 10% level:", num_insignificant_vars))
exper_pvalue <- summary_model$coefficients["exper", "Pr(>|t|)"]
significance_levels <- c(0.001, 0.01, 0.05, 0.1, 0.2)
rejected_levels <- significance_levels[significance_levels > exper_pvalue]
print(paste("The null hypothesis that the coefficient for experience is equal to 0 can be rejected at these significance levels:", paste(rejected_levels * 100, "%", sep = "")))
predictions <- predict(model)
n <- nrow(nba_1)  # Number of observations
manual_mse <- sum((nba_1$wage - predictions)^2) / n  # MSE calculation
# Calculate MSE using Metrics package
metrics_mse <- mse(nba_1$wage, predictions)
print(paste("Manual MSE calculation:", round(manual_mse)))
print(paste("Metrics package MSE:", round(metrics_mse)))
adjusted_r_squared <- summary_model$adj.r.squared
f_statistic <- summary_model$fstatistic[1]
print(paste("Adjusted R-squared:", round(adjusted_r_squared, 2)))
print(paste("F-statistic:", round(f_statistic, 2)))
proportion_eighth_year_or_more <- mean(nba_2$exper >= 8)
rounded_proportion <- round(proportion_eighth_year_or_more, 4)
print(rounded_proportion)
eighth_year_players <- nba_2[nba_2$exper >= 8, ]
probability_million_wage <- mean(eighth_year_players$wage >= 1000)
# Round the result to four decimal places
rounded_probability <- round(probability_million_wage, 4)
# Print the result
print(rounded_probability)
# Ensuring it has the same structure expected by the model
X_new <- with(nba_2, data.frame(exper = exper, age = age, coll = coll, points = points, allstar = allstar))
predicted_wages <- predict(model, newdata = X_new)
n <- nrow(nba_2)  # Number of observations
manual_mse <- sum((nba_2$wage - predicted_wages)^2) / n  # MSE calculation
# Calculate MSE using Metrics package
metrics_mse <- mse(nba_2$wage, predicted_wages)
print(paste("Manual MSE calculation:", round(manual_mse)))
print(paste("Metrics package MSE:", round(metrics_mse)))
# First regression: all predictors
model_full <- lm(wage ~ exper + age + coll + points + allstar, data = nba_2)
summary_model_full <- summary(model_full)
# Identify significant variables at the 5% level
significant_vars <- summary_model_full$coefficients[-1, 4] <= 0.05  # Exclude the intercept
significant_var_names <- names(significant_vars)[significant_vars]
# Ensure to include 'wage' in the subset for the model
significant_var_names <- c("wage", significant_var_names)
# Fit a model using only significant variables
significant_model <- lm(wage ~ ., data = nba_2[, significant_var_names])
# Print summary of the significant model
print(summary(significant_model))
# Non-significant variables for joint hypothesis test
nonsignificant_vars <- !significant_vars  # Adjusted for correct indices
non_sig_formula <- reformulate(names(nonsignificant_vars)[nonsignificant_vars], response = "wage")
# Restricted model with non-significant variables
model_restricted <- lm(non_sig_formula, data = nba_2)
# Joint hypothesis test using anova
anova_results <- anova(model_restricted, model_full)
f_statistic <- anova_results$`F`[2]  # F statistic for the full model component
# Print the F statistic rounded to three decimal places
print(paste("F-statistic:", round(f_statistic, 3)))
# Combine the datasets
combined_nba <- rbind(nba_1, nba_2)
# Calculate minutes per game
combined_nba$minutes_per_game <- combined_nba$minutes / combined_nba$games
# Calculate the mean of minutes per game
mean_minutes_per_game <- mean(combined_nba$minutes_per_game, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean
print(paste("Mean minutes per game:", round(mean_minutes_per_game, 2)))
# Filter for players in their seventh year
seventh_year_players <- combined_nba[combined_nba$exper == 7, ]
# Calculate the mean wage for these players
mean_wage_seventh_year <- mean(seventh_year_players$wage, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean wage
print(paste("Mean seventh year wage:", round(mean_wage_seventh_year, 2)*1000))
# Define the probability of choosing any urn (since all are equally likely)
p_urn <- 1/3
# Define the number of blue balls and total balls in each urn
blue_balls <- c(20, 10, 20)
total_balls <- c(40, 30, 30)
# Calculate the probability of drawing a blue ball from each urn
p_blue_given_urn <- blue_balls / total_balls
# Calculate the total probability of drawing a blue ball
p_blue <- sum(p_blue_given_urn * p_urn)
# Print the probability rounded to two decimal places
print(round(p_blue, 2))
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(stats)
library(Metrics)
nba_1 <- read_csv("/Users/cancel/Personal/Coursework/Econ203/HW11/nba_1-1.csv")
nba_2 <- read_csv("/Users/cancel/Personal/Coursework/Econ203/HW11/nba_2.csv")
# Count the number of guards, forwards, and centers
guard_count <- sum(nba_1$guard)
forward_count <- sum(nba_1$forward)
center_count <- nrow(nba_1) - (guard_count + forward_count)
print(paste("Guards:", guard_count))
print(paste("Forwards:", forward_count))
print(paste("Centers:", center_count))
highest_wage <- max(nba_1$wage)
print(highest_wage*1000)
model <- lm(wage ~ exper + age + coll + points + allstar, data = nba_1)
summary_model <- summary(model)
print(summary_model)
insignificant_vars <- summary_model$coefficients[, 4] > 0.1
num_insignificant_vars <- sum(insignificant_vars)
print(paste("Number of insignificant variables at 10% level:", num_insignificant_vars))
exper_pvalue <- summary_model$coefficients["exper", "Pr(>|t|)"]
significance_levels <- c(0.001, 0.01, 0.05, 0.1, 0.2)
rejected_levels <- significance_levels[significance_levels > exper_pvalue]
print(paste("The null hypothesis that the coefficient for experience is equal to 0 can be rejected at these significance levels:", paste(rejected_levels * 100, "%", sep = "")))
predictions <- predict(model)
n <- nrow(nba_1)  # Number of observations
manual_mse <- sum((nba_1$wage - predictions)^2) / n  # MSE calculation
# Calculate MSE using Metrics package
metrics_mse <- mse(nba_1$wage, predictions)
print(paste("Manual MSE calculation:", round(manual_mse)))
print(paste("Metrics package MSE:", round(metrics_mse)))
adjusted_r_squared <- summary_model$adj.r.squared
f_statistic <- summary_model$fstatistic[1]
print(paste("Adjusted R-squared:", round(adjusted_r_squared, 2)))
print(paste("F-statistic:", round(f_statistic, 2)))
proportion_eighth_year_or_more <- mean(nba_2$exper >= 8)
rounded_proportion <- round(proportion_eighth_year_or_more, 4)
print(rounded_proportion)
eighth_year_players <- nba_2[nba_2$exper >= 8, ]
probability_million_wage <- mean(eighth_year_players$wage >= 1000)
# Round the result to four decimal places
rounded_probability <- round(probability_million_wage, 4)
# Print the result
print(rounded_probability)
# Ensuring it has the same structure expected by the model
X_new <- with(nba_2, data.frame(exper = exper, age = age, coll = coll, points = points, allstar = allstar))
predicted_wages <- predict(model, newdata = X_new)
n <- nrow(nba_2)  # Number of observations
manual_mse <- sum((nba_2$wage - predicted_wages)^2) / n  # MSE calculation
# Calculate MSE using Metrics package
metrics_mse <- mse(nba_2$wage, predicted_wages)
print(paste("Manual MSE calculation:", round(manual_mse)))
print(paste("Metrics package MSE:", round(metrics_mse)))
# First regression: all predictors
model_full <- lm(wage ~ exper + age + coll + points + allstar, data = nba_2)
summary_model_full <- summary(model_full)
# Identify significant variables at the 5% level
significant_vars <- summary_model_full$coefficients[-1, 4] <= 0.05  # Exclude the intercept
significant_var_names <- names(significant_vars)[significant_vars]
# Ensure to include 'wage' in the subset for the model
significant_var_names <- c("wage", significant_var_names)
# Fit a model using only significant variables
significant_model <- lm(wage ~ ., data = nba_2[, significant_var_names])
# Print summary of the significant model
print(summary(significant_model))
# Non-significant variables for joint hypothesis test
nonsignificant_vars <- !significant_vars  # Adjusted for correct indices
non_sig_formula <- reformulate(names(nonsignificant_vars)[nonsignificant_vars], response = "wage")
# Restricted model with non-significant variables
model_restricted <- lm(non_sig_formula, data = nba_2)
# Joint hypothesis test using anova
anova_results <- anova(model_restricted, model_full)
f_statistic <- anova_results$`F`[2]  # F statistic for the full model component
# Print the F statistic rounded to three decimal places
print(paste("F-statistic:", round(f_statistic, 3)))
# Combine the datasets
combined_nba <- rbind(nba_1, nba_2)
# Calculate minutes per game
combined_nba$minutes_per_game <- combined_nba$minutes / combined_nba$games
# Calculate the mean of minutes per game
mean_minutes_per_game <- mean(combined_nba$minutes_per_game, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean
print(paste("Mean minutes per game:", round(mean_minutes_per_game, 2)))
# Filter for players in their seventh year
seventh_year_players <- combined_nba[combined_nba$exper == 7, ]
# Calculate the mean wage for these players
mean_wage_seventh_year <- mean(seventh_year_players$wage, na.rm = TRUE)  # na.rm = TRUE to handle any NA values safely
# Print the rounded mean wage
print(paste("Mean seventh year wage:", round(mean_wage_seventh_year, 2)*1000))
# Define the probability of choosing any urn (since all are equally likely)
p_urn <- 1/3
# Define the number of blue balls and total balls in each urn
blue_balls <- c(20, 10, 20)
total_balls <- c(40, 30, 30)
# Calculate the probability of drawing a blue ball from each urn
p_blue_given_urn <- blue_balls / total_balls
# Calculate the total probability of drawing a blue ball
p_blue <- sum(p_blue_given_urn * p_urn)
# Print the probability rounded to two decimal places
print(round(p_blue, 2))
# Define the probabilities
p_urn <- 1/3
p_blue_given_urn <- c(1/2, 1/3, 2/3)
# Calculate the total probability of drawing a blue ball
p_blue <- sum(p_blue_given_urn * p_urn)
# Calculate the probability of drawing a blue ball from Urn 2
p_blue_given_urn2 <- 1/3
# Apply Bayes' Theorem
p_urn2_given_blue <- (p_blue_given_urn2 * p_urn) / p_blue
# Print the probability rounded to two decimal places
print(round(p_urn2_given_blue, 2))
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
install.packages("tidyverse")
install.packages("quantmod")
install.packages("fredr")
install.packages("tidyverse")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
install.packages("tidyverse")
install.packages("quantmod")
install.packages("fredr")
library(tidyverse)
library(quantmod)
library(fredr)
fredr_set_key("your_fred_api_key")
# Retrieve data from FRED
unemployment_rate <- fredr(series_id = "UNRATE")
install.packages("tidyverse")
knitr::opts_chunk$set(echo = TRUE)
# Check and install necessary packages if not already installed
packages <- c("tidyverse", "quantmod", "fredr")
installed_packages <- rownames(installed.packages())
for (package in packages) {
if (!(package %in% installed_packages)) {
install.packages(package)
}
}
library(tidyverse)
library(quantmod)
library(fredr)
fredr_set_key("your_fred_api_key")
# Retrieve data from FRED
unemployment_rate <- fredr(series_id = "UNRATE")
knitr::opts_chunk$set(echo = TRUE)
# Check and install necessary packages if not already installed
packages <- c("tidyverse", "quantmod", "fredr", "conflicted")
installed_packages <- rownames(installed.packages())
for (package in packages) {
if (!(package %in% installed_packages)) {
install.packages(package)
}
}
library(tidyverse)
library(quantmod)
library(fredr)
fredr_set_key("your_fred_api_key")
# Retrieve data from FRED
unemployment_rate <- fredr(series_id = "UNRATE")
knitr::opts_chunk$set(echo = TRUE)
# Check and install necessary packages if not already installed
packages <- c("tidyverse", "quantmod", "fredr", "conflicted")
installed_packages <- rownames(installed.packages())
for (package in packages) {
if (!(package %in% installed_packages)) {
install.packages(package)
}
}
library(tidyverse)
library(quantmod)
library(fredr)
fredr_set_key("89e09406a6b0e5d39d06d3b19fec5156")
# Retrieve data from FRED
unemployment_rate <- fredr(series_id = "UNRATE")
cpi <- fredr(series_id = "CPILFESL")
hourly_earnings <- fredr(series_id = "CES0500000003")
# Convert the data to time series objects
unemployment_ts <- xts(unemployment_rate$value, order.by = as.Date(unemployment_rate$date))
cpi_ts <- xts(cpi$value, order.by = as.Date(cpi$date))
earnings_ts <- xts(hourly_earnings$value, order.by = as.Date(hourly_earnings$date))
# Calculate year-over-year inflation rate from CPI
inflation_rate <- diff(log(cpi_ts), lag = 12) * 100
# Calculate year-over-year wage inflation rate from hourly earnings
wage_inflation_rate <- diff(log(earnings_ts), lag = 12) * 100
# Merge the data into a single data frame
data <- merge(unemployment_ts, inflation_rate, wage_inflation_rate, all = FALSE)
colnames(data) <- c("Unemployment_Rate", "Inflation_Rate", "Wage_Inflation_Rate")
# Convert to a tidy data frame
data_df <- data.frame(date = index(data), coredata(data))
# Plot Inflation vs. Unemployment Rate
ggplot(data_df, aes(x = Unemployment_Rate, y = Inflation_Rate)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "Inflation vs. Unemployment Rate",
x = "Unemployment Rate (%)",
y = "Inflation Rate (%)")
# Plot Wage Inflation vs. Unemployment Rate
ggplot(data_df, aes(x = Unemployment_Rate, y = Wage_Inflation_Rate)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "Wage Inflation vs. Unemployment Rate",
x = "Unemployment Rate (%)",
y = "Wage Inflation Rate (%)")
# Analyze the relationship between variables
model1 <- lm(Inflation_Rate ~ Unemployment_Rate, data = data_df)
summary(model1)
model2 <- lm(Wage_Inflation_Rate ~ Unemployment_Rate, data = data_df)
summary(model2)
knitr::opts_chunk$set(echo = TRUE)
# Check and install necessary packages if not already installed
packages <- c("tidyverse", "quantmod", "fredr", "conflicted")
installed_packages <- rownames(installed.packages())
for (package in packages) {
if (!(package %in% installed_packages)) {
install.packages(package)
}
}
library(tidyverse)
library(quantmod)
library(fredr)
fredr_set_key("89e09406a6b0e5d39d06d3b19fec5156")
# Retrieve data from FRED
unemployment_rate <- fredr(series_id = "UNRATE")
cpi <- fredr(series_id = "CPILFESL")
hourly_earnings <- fredr(series_id = "CES0500000003")
# Convert the data to time series objects
unemployment_ts <- xts(unemployment_rate$value, order.by = as.Date(unemployment_rate$date))
cpi_ts <- xts(cpi$value, order.by = as.Date(cpi$date))
earnings_ts <- xts(hourly_earnings$value, order.by = as.Date(hourly_earnings$date))
# Calculate year-over-year inflation rate from CPI
inflation_rate <- diff(log(cpi_ts), lag = 12) * 100
# Calculate year-over-year wage inflation rate from hourly earnings
wage_inflation_rate <- diff(log(earnings_ts), lag = 12) * 100
# Merge the data into a single data frame
data <- merge(unemployment_ts, inflation_rate, wage_inflation_rate, all = FALSE)
colnames(data) <- c("Unemployment_Rate", "Inflation_Rate", "Wage_Inflation_Rate")
# Convert to a tidy data frame
data_df <- data.frame(date = index(data), coredata(data))
# Plot Inflation vs. Unemployment Rate
ggplot(data_df, aes(x = Unemployment_Rate, y = Inflation_Rate)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "Inflation vs. Unemployment Rate",
x = "Unemployment Rate (%)",
y = "Inflation Rate (%)")
ggsave("Inflation_vs_Unemployment.png", plot = inflation_vs_unemployment_plot)
knitr::opts_chunk$set(echo = TRUE)
# Check and install necessary packages if not already installed
packages <- c("tidyverse", "quantmod", "fredr", "conflicted")
installed_packages <- rownames(installed.packages())
for (package in packages) {
if (!(package %in% installed_packages)) {
install.packages(package)
}
}
library(tidyverse)
library(quantmod)
library(fredr)
fredr_set_key("89e09406a6b0e5d39d06d3b19fec5156")
# Retrieve data from FRED
unemployment_rate <- fredr(series_id = "UNRATE")
cpi <- fredr(series_id = "CPILFESL")
hourly_earnings <- fredr(series_id = "CES0500000003")
# Convert the data to time series objects
unemployment_ts <- xts(unemployment_rate$value, order.by = as.Date(unemployment_rate$date))
cpi_ts <- xts(cpi$value, order.by = as.Date(cpi$date))
earnings_ts <- xts(hourly_earnings$value, order.by = as.Date(hourly_earnings$date))
# Calculate year-over-year inflation rate from CPI
inflation_rate <- diff(log(cpi_ts), lag = 12) * 100
# Calculate year-over-year wage inflation rate from hourly earnings
wage_inflation_rate <- diff(log(earnings_ts), lag = 12) * 100
# Merge the data into a single data frame
data <- merge(unemployment_ts, inflation_rate, wage_inflation_rate, all = FALSE)
colnames(data) <- c("Unemployment_Rate", "Inflation_Rate", "Wage_Inflation_Rate")
# Convert to a tidy data frame
data_df <- data.frame(date = index(data), coredata(data))
# Plot Inflation vs. Unemployment Rate
inflation_vs_unemployment_plot <- ggplot(data_df, aes(x = Unemployment_Rate, y = Inflation_Rate)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "Inflation vs. Unemployment Rate",
x = "Unemployment Rate (%)",
y = "Inflation Rate (%)")
ggsave("Inflation_vs_Unemployment.png", plot = inflation_vs_unemployment_plot)
# Plot Wage Inflation vs. Unemployment Rate
wage_inflation_vs_unemployment_plot <- ggplot(data_df, aes(x = Unemployment_Rate, y = Wage_Inflation_Rate)) +
geom_point() +
geom_smooth(method = "lm") +
labs(title = "Wage Inflation vs. Unemployment Rate",
x = "Unemployment Rate (%)",
y = "Wage Inflation Rate (%)")
ggsave("Wage_Inflation_vs_Unemployment.png", plot = wage_inflation_vs_unemployment_plot)
# Analyze the relationship between variables
model1 <- lm(Inflation_Rate ~ Unemployment_Rate, data = data_df)
summary(model1)
model2 <- lm(Wage_Inflation_Rate ~ Unemployment_Rate, data = data_df)
summary(model2)
